{"meta":{"title":"JsonLu的个人博客网站","subtitle":"欢迎各位帅哥美女","description":"千淘万洗虽辛苦，吹尽黄沙始到金","author":"JL","url":"http://blog.b6123.top","root":"/"},"pages":[{"title":"关于我","date":"2022-05-10T07:16:40.000Z","updated":"2022-11-01T02:46:06.331Z","comments":true,"path":"about/index.html","permalink":"http://blog.b6123.top/about/index.html","excerpt":"","text":""},{"title":"壁纸","date":"2022-05-07T06:25:21.000Z","updated":"2022-11-01T02:46:06.331Z","comments":true,"path":"bizhi/index.html","permalink":"http://blog.b6123.top/bizhi/index.html","excerpt":"","text":""},{"title":"friends","date":"2022-05-10T06:56:51.000Z","updated":"2022-11-01T02:46:06.332Z","comments":true,"path":"friends/index.html","permalink":"http://blog.b6123.top/friends/index.html","excerpt":"","text":""},{"title":"图库","date":"2022-05-07T06:24:00.000Z","updated":"2022-11-01T02:46:06.332Z","comments":true,"path":"gallery/index.html","permalink":"http://blog.b6123.top/gallery/index.html","excerpt":"","text":"壁纸 收藏的一些壁纸 古典图片 中国古典图片 风景 风景图片"},{"title":"友情链接","date":"2022-05-10T06:58:14.000Z","updated":"2022-11-01T02:46:06.332Z","comments":true,"path":"huoban/index.html","permalink":"http://blog.b6123.top/huoban/index.html","excerpt":"","text":""},{"title":"categories","date":"2022-05-10T07:04:01.000Z","updated":"2022-11-01T02:46:06.331Z","comments":true,"path":"categories/index.html","permalink":"http://blog.b6123.top/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2022-05-10T08:00:03.000Z","updated":"2022-11-01T02:46:06.393Z","comments":true,"path":"me/index.html","permalink":"http://blog.b6123.top/me/index.html","excerpt":"","text":"简介 luyongyu 一名爱作妖，情商为零，面向百度谷歌全栈复制粘贴工程师 工作 农芯（南京）农业研究院 【now~】 联系方式 15155519063"},{"title":"tags","date":"2022-05-10T07:05:03.000Z","updated":"2022-11-01T02:46:06.394Z","comments":true,"path":"tags/index.html","permalink":"http://blog.b6123.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"中级软件设计师知识点","slug":"zjrkzs","date":"2023-03-17T02:46:00.000Z","updated":"2023-03-20T01:38:10.833Z","comments":true,"path":"2023/03/17/zjrkzs/","link":"","permalink":"http://blog.b6123.top/2023/03/17/zjrkzs/","excerpt":"","text":"一 计算机组成计算机硬件基本系统有五大部分组成：运算器，控制器，存储器，输入设备，输出设备。存储器分为内部存储器（即内存，容量小，速度快，临时存放数据）和外部存储器（即硬盘，光盘等，容量大，速度慢，长期保存数据）中央处理单元组成：由运算器，控制器，寄存器组和内部总线组成中央处理单元功能：实现程序控制，操作控制，时间控制，数据处理功能。运算器组成：算术逻辑单元ALU（实现对数据的算术和逻辑运算），累加寄存器AC（运算结果或源操作数的存放区），数据缓冲寄存器DR（暂时存放内容的指令或数据）， 状态条件寄存器PSW（保存指令运行结果的条件码内容，如溢出标志运算器功能：执行所有的算术运算，如加减乘除等。执行所有的逻辑运算并进行逻辑测试，如与，或，非，比较等。控制器组成：指令寄存器IR（暂存CPU执行指令），程序计数器PC（存放下一条执行地址），地址寄存器AR（保存当前CPU所访问的内存地址），指令译码器ID（分析指令操作码）等组成控制器功能：控制整个CPU的工作，最为重要，包括程序控制，时序控制等。 校验码码距：所谓码距，是指一个编码系统中任意两个合法编码之间有多少个二进制位不同 奇偶校验码（只能检一位错，并且不能纠错）奇偶校验码是一种简单有效的检验方法，这种方法通过在编码中增加一位检验位来使编码中1的个数为奇数（奇校验）或者为偶数（偶校验），从而使码距变成2 循环冗余校验码CRC（只能检错，不能纠错）循环冗余校验码广泛应用于数据通信领域和磁介质存储系统。它利用生成多项式为k个数据位产生r个检验位来进行编码，其编码长度为k+r。CRC的代码格式为：由此可知，CRC是由两部分组成，左边为信息位（数据），右边为检验码。若信息码占k位，则检验码占n-k为，检验码是由信息码产生的，检验码的位数越多，改代码的检验能力就越强。在求CRC编码时，采用的是模2运算（按位运算，不发生借位和进位）。 海明码海明码是一种利用奇偶性来检错和纠错的校验方法。海明码的构成方法是在数据位之间的特定位置上插入k个检验位，通过扩大码距来实现检错和纠错。设数据位是n位，检验位是k位，则n和k必须满足以下关系：2k−1≥n+k2^k-1 \\geq n+k2k−1≥n+k 计算机体系结构分类Flynn分类法（理论存在：多指令单数据 MISD） 指令系统CISC是复杂指令系统，兼容性强，指令繁多，长度可变，由微程序实现。RISC是精简指令系统，指令少，使用频率接近，主要依靠硬件实现（通用寄存器，硬布线逻辑控制）具体区别如下： 指令流水线流水线周期：指令分成不同执行段，其中执行最长的为段位流水线周期。流水线执行时间：1条指令的总执行时间+（总指令条数-1）*流水线周期流水线吞吐率：总指令条数&#x2F;流水线执行时间流水线加速比：不使用流水线总执行时间&#x2F;使用流水线总执行时间。 主存编址会算就行了，直接上真题先不用算出来，后面可以化简（B,C） 设备管理设备分类方式按数据组织分类：块设备，字符设备。资源分配角度分类：独占设备，共享设备和虚拟设备。数据传输率分类：低速设备，中速设备和高速设备。I&#x2F;O软件层次结构（越往上越和硬件无关） 输入输出技术程序控制（查询）方式：CPU主动查询外设是否完成数据传输，效率极低。程序中断方式：外设完成数据传输后，向CPU发送中断，等待CPU处理数据，效率相对较高。适用于键盘等实时性较强的场景。中断响应时间是指从发出中断请求到开始进入中断处理程序；中断处理时间是指从中断处理程序开始到中断处理结束，中断向量提供中断处理程序的入口地址。多级中断嵌套，使用堆栈来保护断点和现场。DMA方式（直接主存存取）：CPU只需完成必要的初始化等操作，数据传输的整个过程由DMA控制器来完成，在主存和外设之间建立直接的数据通路，效率很高。适用于硬盘等高速设备。 磁盘调度磁盘调度的目标是使磁盘的平均寻道时间最少常用的磁盘调度算法如下：先来先服务FCFS：根据进程请求访问磁盘的的先后顺序进行调度。此算法的优点是公平，简单，且每个进程都能依次得到处理，缺点是平均寻道时间长。最短寻道时间优先SSTF：请求访问的磁道与当前磁头所在磁道距离最近。使得每次的寻道时间最短。但不能保证平均寻道时间最短。扫描算法SCAN：又称“电梯算法”，磁头在磁盘上双向移动，其会选择离磁头当前所在磁道最近请求访问的磁道，并且与磁头移动方向一致，磁头永远都是从里向外或者从外向里一直移动完才掉头，与电梯类似。单向扫描算法CSCAN:与SCAN不同的是，其只做单向移动，即只能从里向外或者从外向里。 二 软件工程基础知识软件工程基本要素：方法，工具，过程 软件生存周期（常考产出物）可行性分析与项目开发计划这个阶段主要确定软件的开发目标及其可行性参加人员有用户，项目负责人和系统分析师该阶段产生的主要文档有可行性分析报告和项目 开发计划，从而确定系统的逻辑模型 需求分析这个阶段确定软件的系统的功能，性能，数据和界面等要求参加人员有用户，项目负责人和系统分析师。该阶段产生的主要文档软件需求说明书 概要设计在概要设计阶段，开发人员要把确定的各项功能 需求转换需要的体系结构。概要设计就是设计软件的结构概要设计概要的参加人员有系统分析师和软件设计师该阶段主要产生文档有概要设计说明书 详细设计详细设计阶段的主要任务是对每个模块完成的功能进行具体描述，要把功能描述转变为精确的，结构化的过程描述。详细设计阶段的参加人员有软件设计师和程序员。该阶段主要产生文档有详细设计文档。 编码编码阶段就是把每个模块的控制结构转换成计算机课接受的程序代码。即写成某种特定程序设计语言表示的源程序清单 测试测试是保证软件质量的重要手段，其主要方式是在设计测试用例的基础上检查软件的各个组成部分。测试阶段的参加人员通常是另一部门的软件设计师或系统分析师。该阶段主要产生文档有软件测试计划，测试用例和软件测试报告。 软件过程能力成熟度模型CMM能力成熟度模型CMM：对软件组织化阶段的描述，随着软件组织地定义、实施，测量、控制和改进其软件过程，软件组织地能力经过这些阶段逐步提高。 初始级（Initial）：软件过程的特点是杂乱无章，又是甚至很混乱，几乎没有明确定义的步骤，项目的完成全依赖个人的努力和英雄式核心人物的作用。 可重复级（Repeatable）：建立了基本的项目管理过程和实践来跟踪项目费用、进度和功能特性，有必要的过程准则来重复以前在同类项目中的成功。 已定义级（Defined）：管理和工程两方面的软件过程已经文档化、标准化，并综合成整个软件来发组织地标准软件过程，所有项目都采用根据实际情况修改后得到的标准软件过程来开发和维护软件。 已管理级（Managed）：制定了软件过程和产品质量的详细度量标准。软件过程的产品质量都被开发组织地成员所理解和控制。 优化级（Optimized）：加强了定量分析，通过来之过程质量反馈和来自新观念、新技术的反馈使过程能不断持续地改进。 能力成熟度模型CMMI能力成熟度模型CMMI：将已有的几个CMM模型结合在一起，使之构造成为“集成模型”。支持多个工程学科和领域的、系统的、一致的过程改进框架，能适应现代工程的特点和需求，能提高过程的质量和工作效率。阶段式模型：类似于CMM，它关注组织地成熟度，五个成熟度模型如下： 初始的：过程不可预测且缺乏控制。 已管理的：过程为项目服务。 以定义的：过程为组织服务。 定量管理的：过程为以度量和控制。 优化的：集中于过程改进。 维护软件维护是软件设计生存周期中时间最长的阶段。已交付的软件投入正式使用后，便进入软件维护阶段，它可以持续几年甚至十几年。 软件过程模型统一过程模型（UP）统一过程模型：是一种“用例和风险驱动，以架构为中心，迭代并且增量”的开发过程。开发的四个阶段 起始阶段：项目的初始活动，如确认需求和风险评估等。 精化阶段：需求分许和架构设计等。 构建阶段：系统的构建，产生实现模型等。 移交阶段：软件提交方面的工作，产生软件增量，进行β测试，交付系统等。UP的每一次迭代都是一次完整的软件开发过程，包括整个软件开发生命周期，有五个核心工作流（需求-分析-设计-实现-测试）。 瀑布模型结构化方法中的模型，是结构化的开发，开发流程如瀑布一样，一步一步走下去，直到项目完成开发只适用于需求明确或者二次开发（需求稳定）的项目 V模型是瀑布模型的一个变种。特点是增加了多轮测试，并且这些测试贯穿于软件开发的各个阶段 原型快速原型开发，与瀑布模型相反，原型针对需求不明确的情况 螺旋模型是多种模型的混合，针对需求不明确的项目，与原型相似，但增加了风险分析（制定计划—风险分析—实施工程—用户评估） 增量模型首先开发核心功能模块，而后与用户确认，之后再开发次核心功能，即每次开发一部分功能，并与用户需求确认，最终完成项目开发，优先级高的服务最先交付。增量模型的每一次增量版本都可作为独立操作的作品 喷泉模型是一种以用户需求为动力，以对象作为驱动的模型。适用于面向对象的开发方法是开发过程具有迭代性和无间隙性 基于构建的开发模型利于预先包装的构件来构造应用系统，构件是可以组织内部开发的构件，也可以是商品化成品软件构件。提点是增强了复用性，在系统开发过程中，会构建一个构件库，供其他系统复用，因此可以提高复用性，节省时间和成本。 敏捷开发敏捷开发的总体目标是通过“尽可能早，持续地对有价值的软件的交付”使客户满意。通过在软件开发过程中加入灵活性，敏捷开发使用户能够在开发周期的后期增加或者改变需求。 自适应开发（ASD）强调开发方法的适应性 水晶方法（Crystal）水晶法认为每一个不同项目都需要一套不同的策略，约定和方法论 特性驱动开发是一套针对中小型软件开发项目的开发模式，是一个模型驱动的快速迭代开发过程，它强调的是简化，使用，易被开发团队接受，适用于需求经常变动的项目 并列争求法（Scrum）并列争求法是一种迭代的增量化过程，其中，把每30天一次的迭代称为一个“冲刺”，并按需求的优先级来实现产品。 极限编程（XP）XP是一种轻量级（敏捷），高效，低风险，柔性，可预测，科学的软件开发方式。四大价值观：沟通，简单性，反馈和勇气。五个原则：快速反馈，简单性假设，逐步修改，提倡更改和优质工作。12个最佳实践：计划游戏，小型发布，隐喻，简单设计，测试先行，重构，结队编程，集体代码所有制，持续集成，每周工作40小时，现场客户和编码标准 结对编程一个程序员开发，另一个审查代码，能够有效的提高代码的质量 软件工具软件开发工具：对于软件开发过程的各种活动。包括需求分析工具，设计工具，编码与排错工具，测试工具。软件维护工具：辅助软件维护过程中活动的软件，辅助维护人员对软件代码及文档进行各种维护活动。包括版本控制工具，文档分析工具，开发信息库工具，逆向工程工具，再工程工具。软件管理和软件支持工具：辅助管理人员和软件支持人员的管理活动和支持活动，以确保软件高质量完成。包括项目管理工具，配置管理工具，软件评价工具。 软件项目管理有效的项目管理集中在4P上：人员，产品，过程，项目。软件项目估算方法：成本估算方法自顶向下估算：又称类比估算法，确定一个总金额，在向下分摊到每一个功能点。自底向上估算：又称底层功能点开始估算成本，向上累加。差别估算法：与以前的项目相比，找出不同点重新估算，相同点则直接估算。专家估算：聘请专家以其经验对项目整体费用进行估算。COCOMO模型：常见的软件规模估算方法。常用的代码行分析方法作为一种度量估计单位，以代码行数估算每个程序员工作量。累加得软件成本。模型按其详细程度可以可以分为三级：基本COCOMO模型，中间COCOMO模型，详细COCOMO模型。其中基本COCOMO模型是一个静态单变量模型，它用一个以估算出来的原代码行数为自变量的经验函数计算软件开发工作量。中间COCOMO模型在基础COCOMO模型的基础上，再用涉及产品、硬件、人员、项目等方面影响因素调整工作量的估算。详细COCOMO模型包括中间COCOMO模型所有特性，但更进一步考虑了软件工程的每一个步骤的影响。COCOMO II模型：COCOMO模型的升级，也是以软件规模作为成本的主要因素，考虑多个成本驱动因子。该方法包括三个阶段性模型，即应用组装模型，早期设计阶段模型，体系结构阶段模型Putnam估算模型：一种动态多变量模型，假设在软件开发的整个生存周期中工作量有特定的分布。 进度管理基本原则：划分，相互依赖，时间分配，工作量确认，确认责任，明确输出结果，确定里程碑。Gantt图：又称横道图，横轴表示时间，纵轴表示活动，以时间顺序表示活动，能反应活动间的并行关系，但无法反应活动间的依赖关系，因此也难以清晰的确定关键任务和关键路径。PERT图：类似前趋图，是有向图，反应活动间的依赖关系，有向边上标注活动的运行时间，但无法反应活动间的并行关系。PERT图关键路径：最早开始时间ES：取所有前驱活动最早完成时间EF的最大值。最早完成时间EF：ES+DU（活动本身时间）。关键路径（项目总工期）：项目中耗时最长的线路。最晚完成时间LF：取后续活动最晚开始时间的最小值。最晚开始时间LS：LF-DU松弛时间：LS-ES 或者LF-EF （即活动最多可以晚几天开始）关键路径为图中最长的路径即 D-F-H 权值为48所以第一空选CFG的松弛时间为 关键路径 - 包含FG的最长路径 （DFH）-（DFG）&#x3D;48-28&#x3D;20 所以第二空为B 软件项目的组织程序设计小组的组织方式：主程序员制小组：主程序员全权负责，后援工程师有必要时能替代主程序员，适合大规模项目。民主制小组：也即无主程序员小组，成员之间地位平等，任何决策都是全员参与投票，适合于项目规模小，开发人员少，采用新技术和确定性较小的项目。层次式小组：两个层次，一名组长领导若干个高级程序员，每个高级程序员领导若干个程序员。 软件质量管理 质量特性 质量子特性 功能性 适合性 准确性 互用性 依从性 安全性 可靠性 成熟性 容错性 易恢复性 易使用性 易理解性 易学性 易操作性 效率 时间特性 资源特性 可维护性 易分析性 易改变性 稳定性 易测试性 可移植性 适应性 易安装性 一致性 易替换性 可维护性（常考）易分析性：与为诊断缺陷或失效原因，或为判定待修改部分所需那里有关的软件属性。易改变性：与进行修改、排错、或适应环境变换所需努力有关的软件属性。稳定性：与修改造成未预料效果风险有关的软件属性。易测试性：为确认经修改软件所需努力有关的软件属性。 软件容错技术通常将质量理解为用户满意程度，为了使用户满意，有两个必要条件：设计的规格说明书符合用户标准，称为设计质量。程序按照设计规模书所规定的情况正确执行，称为程序质量。设计质量评审，程序质量评审软件容错技术：容错就是软件遇到错误的处理能力，实现容错的手段主要是冗余，包括下面四种冗余技术：结构冗余：分为静态（通过表决和比较，少数服从多数）、动态（多重模块待机备份，故障是切换备份机）、混合冗余（二者综合）。信息冗余：为检错和纠错在数据中加上一段额外的信息，例如检验码原理。时间冗余：遇到错误是重复执行，例如回滚，重复执行还有错，则转入错误处理逻辑。冗余附加技术：冗余附加技术是指为实现数据结构，信息和时间冗余技术所需的资源和技术，包括程序，指令，数据，存放和调动它们的空间和通道等 风险管理风险管理两个特性：不确定性（可能发生也可能不发生）、损失（发生会产生恶性后果）。项目风险威胁到项目计划，如果项目风险发生，有可能拖延项目的进度和增加项目的成本，指预算。进度、人员、资源。利益相关者、需求等方面的潜在问题以及它们对软件项目的影响。项目复杂度、规模及结构不确定性也属于项目风险因素。技术风险威胁到要开发软件的质量和交付时间，如果技术风险发生，开发工作就变得很困难或者不可能，只设计、实现、接口、验证和维护等方面的潜在问题。此外，规格说明的歧义性，技术的不确定性，技术陈旧以及“前沿”技术也是技术风险因数。商业风险威胁到要开发软件的生存能力，包括下面五种： 市场风险：开发了一个没有人真正需要的优良产品或系统。 策略风险：开发的产品不在符合公司的整体商业策略。 销售风险：开发了一个销售部门不知道该如何销售的产品。 管理风险：由于重点的转移或人员变动而失去了高级管理层的支持。 预算风险：没有得到预算或人员的保证。 风险管理过程如下： 风险识别：识别出项目中已知和可预测的风险，确定风险的来源，产生的条件，描述风险的特征以及哪些项目可以产生风险。形成一个风险列表。 风险预测：又称为风险估计，从两个方面预测风险，即风险可能发生的概率和风险产生的后果，因此有风险曝光度&#x3D;风险发生的可能性*风险发生带来的损失。 风险评估：定义风险参照水准，将识别出来的风险评估分类。 风险控制：辅助项目组建立处理风险的策略，包括风险避免，风险监控，RMMM计划（风险缓解，监控和管理计划） 软件度量软件的两种属性：外部属性指面向管理者和用户的属性，可直接测量，一般为性能指标。内部属性指软件产品本身的属性，如可靠度等，只能间接测量。McCabe算法：又称为环路复杂度，假设有向图中有向边数为M，节点数为N，则此有向图的环路复杂度为M-N+2。 三 计算机网络和多媒体计算机网络的概念计算机网络是计算机技术与通信技术相结合的产物，它实现了远程通信，远程信息处理和资源共享。计算机网络的功能：数据通信，资源共享，负载均衡，高可靠性。计算机网络的分类： 局域网（LAN）：传输速率 4Mbps~1Gbps 城域网（MAN）：传输速率 50Kbps~100Mbps 广域网（WAN）：传输速率 9.6Kbps~45Mbps 网络的拓扑结构总线型（利用率低，干扰大，价格低）星型（交换机形成的局域网，中央单元负荷大）环型（流动方向固定，效率低扩展难）树型（总线型的扩充 ，分级结构）分布式（任意节点连接，管理难成本高） OSI七层模型从下往上依次是：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。 物理层：二进制数据传输，物理链路和物理特性相关。 数据链路层：将数据封装成帧进行传输，准确传送至局域网内的物理主机上。 网络层：数据分组传输和路由选择，能准确的将数据传输到互联网的主机上。 传输层：端到端的链接，传送数据至主机端口上。 会话层：管理主机之间的会话，提供会话管理服务。 表示层：提供解释所交换数据的含义的服务，包括数据之间的格式转换，压缩，加密等操作，对数据进行处理。 应用层：实现具体的应用功能，直接进程间的通信。 网络互联硬件物理层：中继器（扩大信号），集线器Hub（多路中继器）数据链路层：网桥（分析帧地址），交换机（多路网桥，MAC地址表）网络层：路由器（连接多个逻辑上分开的网络，路由选择）应用层：网关（连接不同类型且协议差别较大的网络，协议转换）传输介质：有线介质：双绞线（ 最大长度100m，每端需要一个RJ45插件），同轴电缆，光纤。无线介质：微波，红外线和激光，卫星通信。 局域网协议IEEE802.3 :标准以太网 速度为10Mbps，传输介质是同轴电缆。IEEE802.3u: 快速以太网 速度为100Mbps 传输介质是双绞线。IEEE802.3z:千兆以太网 速度为1000Mnps 传输介质是光纤或双绞线。 TCP&#x2F;IP协议族特性：逻辑编址，路由选择，域名解析，错误检测和流量控制。TCP&#x2F;IP分层模型 应用层：具体应用功能。 传输层：提供应用程序间端对端的通信。 网际层：又称IP层，处理机器间的通信，数据以分组为单位。 网络接口层：又称数据链路层，负责接收IP数据报，并把数据报通过选定的网络发送出去。 网络层协议IP协议：最重要最核心的协议（无连接，不可靠）ICMP协议：因特网控制信息协议，检测网络通信顺畅ARP协议和RARP协议：地址解析协议和反地址解析协议ARP IP地址 -&gt; 物理地址RARP 物理地址 -&gt;IP地址 传输层协议&#x3D;&#x3D; UDP协议：不可靠链接， 一般用于视频，音频传输TCP协议：可靠连接 （三次握手协议）&#x3D;&#x3D; 应用层协议基于TCP的FTP，HTTP都是可靠传输，基于UDP的DHCP，DNS都是不可靠传输。FTP：文件传输协议（可靠）控制端口为21 传输端口为20HTTP（默认端口80）：超文本传输协议 （可靠）使用SSL加密后为HTTPS（默认端口443）SMTP（发送）和POP3（收取）：邮件传输协议（可靠） 邮件报文采用ASCLL格式表示Telent：远程连接协议（可靠）TFTP：小文件传输协议（不可靠）SNMP：简单网络管理协议（不可靠）DHCP：动态分配IP地址协议（不可靠）客户机&#x2F;服务器模型 默认租期为8天DNS：域名解析协议（不可靠）将域名解析成IP地址 IP地址分类地址格式：IP地址分为四段，每段八位，共32位二进制数组成。在逻辑上，这32位IP地址分为网络号和主机号，依据网络号位数不同，可以将IP地址分为一下几类： A类：0.0.0.0~127.255.255.255 （八位网络号，主机号位32-8，能分配的主机号个数为2^24-2个，全0和全1不能分配） B类：128.0.0.0~191.255.255.255（16位网络号） C类：192.0.0.0~223.255.255.255（24位网络号） D类组播：224.0.0.0~239.255.255.255 E类保留：240.0.0.0~255.255.255.255IPV6地址长度为128位，地址空间增加了2^96倍。 防火墙防火墙是内部网络和外部因特网之间增加的一道安全防护措施，它认为内部网络是安全的，外部网络是不安全的。分为网络级防火墙和应用级防火墙，两级之间的安全手段如下所示：网络级防火墙（包过滤防火墙）层次低，但是效率高，因为其使用包过滤和状态监测手段，一般只检验网络包外在（起始地址，状态），属性是否异常，若异常，则过滤掉，不与内网通信，因此对用户和应用是透明的。如果遇到伪装的危险数据包就没办法过滤掉。应用及防火墙（代理服务器防火墙）：层次高，效率低，因为应用级防火墙会将网络包拆开，具体检查里面的数据是否有问题，会消耗大量的时间，造成效率低下，但是安全强度高，包括双宿主主机，屏蔽主机网关被屏蔽子网等方法。被屏蔽子网方法，是在内网和外网之间增加了一个屏蔽子网，相当于多了一层网络，称为DMZ（非军事区），这样内网和外网通信必须多经过一道防火墙，屏蔽子网中一般存放的是邮件服务器，WEB服务器这些内外网数据交互的服务器，可以屏蔽掉一些来自内部的攻击，但是完全来自系统内部服务器的攻击还是无法屏蔽掉。 计算机病毒和木马病毒：编制或在计算机程序中插入的破坏计算机功能或者破坏数据，影响计算机使用并且能够自我复制的一组计算机指令和或程序代码。病毒具有：传染性，隐蔽性，潜伏性，破坏性，针对性，衍生性，寄生性，未知性。木马：是一种后门程序，常被黑客用作控制远程计算机的工具，隐藏在被控制电脑上的一个小程序监视电脑一切操作并盗取数据。病毒和木马的种类系统引导型病毒文件外壳型病毒目录型病毒蠕虫病毒（感染EXE文件 可执行文件）：熊猫烧香，罗密欧与朱丽叶，恶魔，尼姆达，冲击波木马：QQ消息尾巴木马，特洛伊木马，冰河。宏病毒（感染word，Excel等文件）：美丽沙，台湾一号。CIH病毒：史上唯一破坏硬件的病毒。红色代码（蠕虫病毒+木马） 网络安全网络安全的五大要素:保密性，完整性，可用性，可控性，不可抵赖性。 网络攻击重放攻击（ARP）：所截获某次合法的通信数据拷贝，出于非法的目的而被重新发送。拒绝服务（DOS）：对信息或其他资源的合法访问被无条件阻止。旁路控制：攻击者利用系统的安全缺陷或安全性上的脆弱之处获得非授权的权利或特权。授权侵犯：被授权以某一目的使用某一系统或资源的某个人，却将此权限用于其他非授权的目的，也称作“内部攻击”。特洛伊木马：软件中含有一个察觉不出或者无害的程序段，当它被执行时，会破坏用户的安全。窃听：用各种可能合法或非法的手段窃取系统中的信息资源或敏感信息。业务流分析：通过对系统的长时间监听，利用统计分析方法对诸如通信频度，通信的信息流向，通信总量的变化等参数进行研究，从而发现有价值的信息和规律。信息泄露：信息被泄露或透露给某个未授权的实体。破坏信息完整性：数据被非授权的 进行增删，修改或破坏而受到损失。 加密技术基本概念：明文：实际传输的真正数据。密文：经过加密后的数据。加密：将明文转换为密文的过程。解密：将密文转换为明文的过程。加密算法：一般是公开的。包括两大规则：代换（转换为完全不同的数据），置换（打乱明文顺序，进行重新置换）秘钥：加密和解密过程中使用的密码等，是隐藏的。对称加密技术：对数据加密和解密的秘钥是相同的，也称为共享秘钥加密技术。属于不公开秘钥加密算法。其缺点是加密安全性不高（因为只有一个秘钥）且秘钥分发困难。但是其加密快，适合大数据的加密。常见的对称加密算法如下：DES:替换+移位，56位秘钥，64位数据块，速度快，秘钥易产生。3DES（三重DES或称TDEA）：两个56位秘钥K1,K2加密：K1加密-&gt;K2解密-&gt;K1加密加密：K1解密-&gt;K2加密-&gt;K1解密AES:AES算法是基于排序和置换运算。是美国联邦政府采用的一种区块加密标准。RC-5：RSA数据安全公司的很多产品都使用了RC-5。IDEA算法：128位秘钥，64位数据块，比DES加密性好，对计算机功能要求相对低。非对称加密技术：又称公开秘钥加密技术，非对称加密技术的保密性好，它消除了最终用户交换 秘钥的需要，但加密解密花费的时间长，速度慢，不适合对文件加密，而只适合对少量数据进行加密。公钥体系中，公钥是用于加密和认证，私钥用于解密和签名。常见的非对称加密算法如下：RSA：512位或1024位秘钥，计算量极大，难破解。Elgamal：其基础是Diffie-HEllman秘钥交换算法。ECC：椭圆曲线算法。其他非对称算法：背包算法，Rabin，D-H。 常见网络诊断命令ping：用于检查网络是否连通；tracert( linux: traceroute)：用于确定 IP数据包访问目标所采取的路径，若网络不通，能定位到具体哪个结点不通；ipconfig（linux: ifconfig）：显示TCP&#x2F;IP网络配置值，如：IP地址，MAC地址，网关地址等；nslookup：查询DNS记录；Netstat：用于显示网络连接、路由表和网络接口信息。 多媒体基本概念媒体可分为下面五类： 感觉媒体：直接作用于人的感官器官，使人产生直接感觉的媒体。如视觉，听觉，触觉等。 表示媒体：指传输感觉媒体的中介媒体，即用于数据交换的编码。如文字，图形，动画，音频，和视频等 表现媒体：进行信息输入和信息输出的媒体。如键盘，鼠标和麦克风；显示器，打印机和音响等， 存储媒体：存储表示媒体的物理介质，如磁盘，光盘和内存等 传输媒体：传输表示媒体的物理介质，如电缆，光纤，双绞线等 声音 人耳能听到的音频信号的频率范围是20Hz~20KHz。声音的采样频率一般为最高频率的两倍，才能保证不失真声音文件格式：.wav 、.snd 、.au 、.aif 、.voc 、.mp3 、.ra 、.mid等 图形和图像颜色三要素：亮度：彩色明暗深浅程度。色调（红，绿）：颜色的类别。饱和度：某一颜色的深浅程度。图像的属性：分辨率（每英寸像素点dpi），像素深度（存储每个像素所使用的的二进制位数）图像文件格式：.bmp、.gif 、.png 、.jpg、.tif、.wmf等图像深度是图像文件记录一个像素点所需要的的位数，显示深度表示显示缓存中记录屏幕上一个点的位数（bit），也即显示器可以显示的颜色数水平分辨率：显示器在横向上具有的像素点数目。垂直分辨率：显示器在纵向上具有的像素点数目。矢量图的基本组成单位是图元，位图的基本组成单位是像素，视频和动画的基本组成单位是帧。 多媒体计算 四 操作系统进程的组成和状态进程的组成：进程控制块PCB（唯一标志），程序（描述程序要干什么），数据（存放进程执行是所需数据）。三态图和五态图系统自动控制时只有三种状态，人为操作才有五种状态 前趋图前趋图：用来表示哪些任务可以并行执行，哪些任务之间有顺序关系。如下图：如图可知，A,B,C可以并行执行，而D要等A,B,C执行完了才能执行。 进程资源图进程资源图：用来表示进程和资源之间的分配和请求关系。如下图所示:P代表进程，R代表资源，R方框中 有几个圆球就表示有几个这种资源，在图中，R1指向P1，表示R1已经分配了一个资源给P1了，P1指向R2，表示P1还需要一个R2才能执行。阻塞节点：某进程中所请求的资源已全部分配完毕，无法获取所需资源，则该进程被阻塞了无法继续执行，如上图P2。非阻塞节点：某进程所请求的资源还有剩余，可以分配给该进程继续运行。如上图中P1,P3。当一个进程资源图中所有进程都是阻塞节点时，即进入死锁状态。 死锁当一个进程在等待永远不可能发生的事件时，就会产生死锁，若系统中多个进程出于死锁状态，就会造成系统死锁。死锁产生的必要条件： 资源互斥 每个进程占有资源并等待其他资源 系统不能剥夺进程资源 进程资源图是一个环路 死锁产生后，解决措施是打破四大条件，有下列方法：死锁预防：采用某种策略限制并发进程对于资源的请求，破坏死锁的四大条件之一，使系统任何时候都不满足死锁的条件。死锁避免：一般采用银行家算法来避免。银行家算法，就是提前计算出一条不会死锁的资源分配方法，才分配资源，否则不分配资源。死锁检测：允许死锁产生，当系统定时运行一个检测死锁的程序，若检测到系统中发生死锁，则设法加以解除。死锁解除：即死锁发生后的解除办法，如剥夺资源，撤销进程等。死锁计算问题：系统内有你n个进，每个进程需要R个资源，那么其发生死锁的最大资源数为n∗(R−1)n*(R-1)n∗(R−1)。其不发生死锁的最小资源数为n∗(R−1)+1n*(R-1)+1n∗(R−1)+1. 线程传统的线程有两个属性：可拥有资源的独立单位，可独立调度和分配的基本单位。引入线程后，线程是独立调度的最小单位，进程是拥有资源的最小单元。线程可以共享进程的公共数据，全局变量，代码，文件等资源，但不能共享线程独有的资源，如线程的栈指针等标识数据。 五 数据库技术基础基本概念数据库系统DBS：是一个采用了数据库技术，有组织地，动态地存储大量相关数据，方便多用户访问的计算机系统。其由以下四个部分组成：数据库（统一管理，长期存储在计算机内的，有组织的相关数据集合）硬件（构成计算机系统的各种物理设备，包括存储数据所需的外部设备）软件（操作系统，数据库管理系统及应用程序）人员（系统分析和数据库设计人员，应用程序员，最终用户，数据库管理员DBA ） 三级模式-两级映象内模式：内模式也称存储模式，是数据物理结构和存储方式的描述，是数据在数据库内部的表示方法（存储文件），定义所有的内部记录类型，索引和文件的组织方式。概念模式：概念模式也称模式，就是我们通常使用的基本表，根据应用，需求将物理数据划分一张张表。外模式：对应数据库中视图这个级别，将表进行一定处理后在提供给用户使用。模式&#x2F;内模式映象：存在于概念级和内部级之间，实现了概念模式和内模式之间的相互转换。外模式&#x2F;模式映象：存在于外部级和概念级之间，实现了外模式和概念模式之间的相互转换。 数据库设计需求分析：即分析数据存储的要求，主要产出物有数据流图，数据字典，需求说明书。概念结构设计：就是设计E-R图，即实体-属性图，与物理实现无关，说明有哪些实体，哪些属性，逻辑结构设计：将E-R图转成关系模式，即转换为实际的表和表中的列属性。物理设计：根据生成的表等概念，生成物理数据库。 E-R模型E-R模型：即实体-联系模型，使用椭圆表示属性（一般没有），长方形表示实体。菱形表示联系，联系两端要标注联系类型。联系类型：一对一1:1，一对多1：N，多对多N:M。属性分类：简单属性和复合属性（属性是否可以分割），单值属性和多值属性（属性是否有多个取值），NULL属性（无意义），派生属性（可由其他属性得来）。 关系模型关系模型即数据库中常用的表，包括实体的属性，标识出实体的主键和外键。实例如下：E-R图转换为关系模式：每个实体都对应这种关系模式，联系分为三种：1:1关系中，联系可以放在任意两端的实体中，作为一个属性（要保证1:1的两端要关联）。1:N关系中，联系可以单独作为一个关系模式，也可以在N端中加入1端实体的主键。N:M关系中，联系必须作为一个单独的关系模式，其主键是N和M端的联合主键。 关系代数运算并∪：结果是两张表所有记录的合并，相同记录只显示一次。交∩：结果是两张表中相同的记录。差-：S1-S2，结果是S1表中有而S2表中没有的记录。笛卡尔积(×):S1×S2，产生的结果包括S1和S2的所有属性列，并且S1中的每条记录依次和S2中所有记录组合成一条记录，最终属性列为S1+S2属性列，记录数为S1*S2记录数。投影(π)：实际是按条件选择某关系模式中的某列，列也可以用数字表示。选择(σ)：实际是按条件选择某关系模式中的某条记录。自然连接：自然连接的结果是显示全部的属性列，但相同的属性列只显示一次，显示两个关系模式中属性相同且值相同的记录。 函数依赖给定一个X，能唯一确定一个Y，就称X确定Y，或者说Y依赖于X。函数依赖又可以扩展一下两种规则：部分函数依赖：A可以确定C，（A,B）也可以确定C。（A,B）中的一部分（即A）可以确定C，称为部分函数依赖。传递函数依赖：当A和B不等价时，A可确定B，B可确定C，则A可以确定C，是传递函数依赖。 键与约束超键：能唯一标识此表的属性的组合。候选键：超键中去掉冗余的属性，剩余的属性就是候选键。主键：任选一个候选键，即可作为主键。外键：其他表中的主键。主属性：候选键内的属性为主属性，其他属性为非主属性。实体完整性约束：即主键约束，即主键不能为空，也不能为空。参照完整性约束：即外键约束，外键必须是其他表中已经存在的主键的值，或者为空。用户自定义完整性约束：自定义表达式约束，如年龄限制在0~150。 范式第一范式1NF：若关系模式R的没一个分量是不可再分的数据项，则关系模式R∈1NF。第二范式2NF：若关系模式R∈1NF，且每一个非主属性完全依赖主键（不存在部分函数依赖）时，则关系模式R∈2FN。第三范式3NF：若关系模式R∈2FN，且R中没有非主属性传递依赖于候选键时，则关系模式∈3NF。一般解决方式是拆分传递依赖的非主属性为一个新的关系模式。本质就是主键要直接决定所有非主属性，不能通过非主属性间接决定。BC范式BCNF：不存在函数依赖，也不存在传递依赖。 事务管理事务：由一系列操作组成，这些操作“要么都做，要么什么都不做”，拥有四种特性，如下原子性（操作）：要么全做，要么全不做。一致性（数据）：事务发生后数据是一致的。隔离性（执行）：任一事务的更新操作直到其成功提交的整个过程对其他事务都是不可见的，不同事务之间是隔离的，互不干涉。持续性（改变）：事务操作的结果是持续性的。事务开始begin transaction，事务提交commit ，事务回滚rollback。 并发控制所谓并发控制，是指在多用户共享的系统中许多用户可能同时对同一数据进行操作。并发操作带来的问题是数据的不一致性，主要有三类：丢失更新，不可重复读，读脏数据。 并发控制技术并发控制的主要技术是封锁，基本封锁的类型有排他锁（简称X锁或者写锁）和共享锁（简称S锁或者读锁）。排它锁：若事务T对数据对象A加上X锁，则只允许T读取和修改A，其他事务都不能再对A加任何类型的锁，直达T释放A上的锁。共享锁：若事务T对数据对象A加上S锁，则只允许T读取A，但不能修改A，其他事务只能在对A加S锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A进行任何修改。 三级封锁协议一级封锁协议：事务在修改数据R前必须对其加X锁，直到事务结束才释放。一级封锁协议可以解决丢失更新问题二级封锁协议：在一级封锁协议的基础上，加上事务T在读数据R前必须先对其加S锁，读完后立即释放S锁。二级封锁协议可以解决读脏数据的问题三级封锁协议：在一级封锁协议的基础上，加上事务T在读数据R前必须先对其加S锁，直到事务结束时释放S锁。三级封锁协议除了防止修改和不读“脏”数据外，还进一步防止了不可重复读。 分布式数据库局部数据库位于不同的物理位置，使用一个全局的DBMS将所有局部数据库联网管理，这就是分布式数据库。其体系结构如下图所示：分片模式水平分片：将表中水平的记录分别存在不同的地方。垂直分片：将表中的垂直的列值分别存在不同的地方。分布式透明性分片透明性，用户或应用程序不需要知道 逻辑上存储的表具体是如何分块存储的。位置透明性：应用程序不关心数据存储物理位置的改变。逻辑透明性：用户或应用程序无需知道局部使用的是哪种数据结构。复制透明性：用户或应用程序不关心复制的数据从何而来。 数据仓库数据仓库是一种特殊的数据库，也是按数据库形式存储数据，但是目的不同，数据库经过长时间的运行，里面的数据会越存越多，就会影响数据库的运行效率，对于某些程序而言，很久之前的数据并非必要的，因此，可以删除掉减少数据，增加效率，考虑到删除这些数据比较可惜，因此，一般将这些数据库提取出来保存到另一个数据库中，称为数据仓库。数据仓库的目的不是为了应用，是面向主题的，用来做数据分析，集成不同表，而且是相对稳定的，一般不会做修改，同时会在特定的时间点做大量的插入，反应历史的变化。形成数据仓库后，有两个作用，一个是用来做数据的查询、分析、生成报表，另一个是使用数据挖掘工具对这些历史数据进行挖掘，查询数据之间的关系，发现剩余价值。数据挖掘的分析方法关联分析：关联分析主要用于发现不同事物之间的关联性，即一个事物发生的同时，另一个事物也经常发生。序列分析：序列分析主要用于发现一定时间间隔内接连发生的事件，这些事件构成一个序列，发现的序列应该具有普遍意义。分类分析：分类分析通过分析具有类别的样本特点，得到决定样本属于各种类别的规则或方法。分类分析时首先为每个记录赋予一个标记，即按标记分类记录，然后检查这些标定的记录，描述出这些记录的特征。聚类分析：聚类分析师根据“物以类聚”的原理，将本身没有类别的样本聚集成不同的组，并且对每个这样的组进行描述的过程。 反规范化技术规划化操作可以防止插入异常，更新，删除异常和数据冗余，一般是通过模式分解，将表拆分，来达到这个目的。但是表拆分后，解决了上述异常，却不利于查询，每次查询时，可能都要关联很多表，严重降低了查询效率，因此，有时候需要反规划技术来提高查询效率。技术手段包括：增加派生性冗余列，增加冗余列，重新组表，分割表。主要就是增加冗余，提高查询效率，为规划化操作的逆操作。 SQL语句增 create 删 delete 改 update 查 select数据库查询select…（属性）…from…（表名）…where （条件）分组查询group by 分组是要注意select后的列名要适应分组，having为分组附加条件:select sno,avg from student group by sno having(avg&gt;60)更名运算 as: select sno as “学号” from t1字符串匹配 like，%匹配多个字符，_匹配任意一个字符排序 order by：默认为升序，降序要加关键字desc：select * from order by sno desc。 六 程序设计语言基础知识程序设计语言是为了书写计算机程序而人为设计的符号语言，用于对计算过程进行描述、组织和推导。低级语言：机器语言（计算机硬件只能识别0,1的指令序列），汇编语言。高级语言：功能更强，抽象级别更高，与人们使用的自然语言比较接近。各程序语言的设计特点： Fortran语言（科学计算，执行效率高） Pascal语言（为教学而开发的，表达能力强，Delphi） C语言（指针操作能力强，高效） Lisp语言（函数式程序语言，符号处理，人工智能） C++语言（面向对象，高效） Java语言（面向对象，中间代码，跨平台） C#语言（面向对象，中间代码，.net） Prolog语言（逻辑推理，简洁性，表达能力，数据库和专家系统） 解释与编译：都是将高级语言翻译成计算机硬件认可的机器语言加以执行，不同之处在于编译程序生成独立的可执行文件，直接运行，运行时无法控制源程序，效率高。而解释程序不生成可执行文件，可以逐条解释执行，用于调试模式，可以控制源程序，因为还需要控制程序，因此执行速度慢，效率低。程序设计语言组成：语法（一组规则），语义（语法成分的含义），语用（构成语言的各个标记和使用者的关系）。 程序设计语言的基本成分数据成分：指一种程序设计语言数据和数据类型，数据分为常量（程序运行时不可改变），变量（程序运行可以改变），全局变量（存储空间在静态数据区分配），局部变量（存储空间在堆栈区分配）。数据类型有整型，字符型，双精度浮点型，单精度浮点型，布尔型等。运算成分：指明允许使用的运算符号及运算规则。包括算术运算，逻辑运算，关系运算，位运算等。控制成分：指明语言允许表述的控制结构。包括顺序结构，选择结构，循环结构，传输成分：指明语言允许的数据传输方式。如赋值处理，数据的输入输出等。 函数函数：C程序有一个或多个函数组成，每个函数都有一个名字，其中有且仅有一个的main函数作为程序的入口。函数式程序模块的主要成分，是一段具有独立功能的程序。函数涉及三个概念：函数定义，函数声明，函数调用。传值调用：将实参的值传递给形参，形参的改变不会导致调用点所传实参的值改变。实参可以是变量，常量和表达式。传址调用：即引用调用，将实参的地址传递给形参，即相当于实参存储单元的地址引用，因此其值改变的同时就改变的实参的值。实参的值不能为常量，只能是合法的变量或表达式。 编译程序基本原理编译程序的功能是把某高级语言书写的源程序翻译成与之等价的目标程序（汇编语言和机器语言）。编译程序工作过程分为6个阶段，如下图所示：词法分析：这个阶段的任务是从左到右一个一个字符地读入源程序，即対构成源程序的字符流进行扫描然后根据构词规则识别单词（也称单词符号或符号）语法分析：是编译过程的一个逻辑阶段。语法分析的任务是在词法分析的基础上将单词序列组合成各类语法短语，如“程序”、“语句”、“表达式”等等，语法分析程序判断源程序在结构上是否正确。语义分析：是编译过程的一个逻辑阶段，语义分析的任务是对结构上正确的源程序进行上下文有关性质的审查。如类型匹配、除法除数不为0等。有分为静态语义错误（在编译阶段能够查找出来）和动态语义错误（只能在运行时发现）中间代码和目标代码生成：中间代码是根据语义分析产生的，需要经过优化链接，最终生成可执行的目标代码。引入中间代码的目的是进行与机器无关的代码优化处理，常用的中间代码有后缀式（逆波兰式）、三元式（三地址码）、四元式、图和树等形式。 编译程序基本原理主要掌握上述三种表达式即可，其实就是树的三种遍历，一般正常的表达式是中序遍历，即中缀表达式，根据其构造出树，再按题目要求求出前缀或后缀式。简单求法：后缀表达式是从左往右开始，先把表达式加上括号，再依次把运算符加到本层次的括号后面。 文法定义终结符：最终结果，不能推导出其他元素。非终结符：能够推导出其他元素。产生式：即非终结符推导出终结符的公式。闭包：概念如下图。一般考察闭包可以为0个的情况代入运算： 正规式 有限自动机确定的有限自动机和不确定的有限自动机：输入一个字符，看是否能得到唯一的后继，若能，则是确定的，否则若得出多个后继，则是不确定的。 七 系统开发与运行系统分析概述系统分析是一种问题的求解技术，它将一个系统分解成各个组成部分，目的是研究各个部分如何工作，交互，以实现其系统目标。目的和任务：系统分析的主要任务是对现行系统进一步详细调查，将调查中所得到的文档资料集中，对组织内部整体管理状况和信息处理过程进行分析，为系统开发提供所需资料，并提交系统方案说明书。系统分析的主要步骤 认识、理解当前的现实环境，获得当前系统的“物理模型”。 从当前系统的“物理模型”抽象出当前系统的“逻辑模型”。 对当前系统的“逻辑模型”进行分析和优化，建立目标系统的“逻辑模型”。 对目标系统的逻辑模型具体化（物理化），建立目标系统的物理模型。 系统开发的目的是将现有系统的物理模型转换为目标系统的物理模型。 系统设计系统设计基本原理：抽象（重点说明本质问题，忽略非本质方面）模块化（可组合、分解和更换的单元）信息隐蔽（将每个程序的成分隐蔽或封装在一个单一的设计模块中）模块独立（每个模块完成一个相对独立的特定子功能，且与其他模块之间的联系简单）模块的设计要求独立性高，就必须高内聚，低耦合，内聚是指一个模块内部功能之间的相关性，耦合是指多个模块之间的联系。 内聚内聚程度从低到高如下表所示： 内聚分类 定义 记忆关键字 偶然内聚 一个模块内各处理元素之间没有任何联系 无直接关系 逻辑内聚 模块内执行若干个逻辑上相似的功能，通过参数确定改模块完成哪一个功能 逻辑相似，参数决定 时间内聚 把需要同时执行的动作组合在一起形成模块 同时执行 过程内聚 一个模块完成多个任务，这些任务必须按指定的过程执行 指定的过程顺序 通信内聚 模块内所有处理元素都在同一个数据结构上操作，或者各处理使用相同的输入数据或产生相同的输出数据 相同的数据结构、形同的输入输出 顺序内聚 一个模块中各个处理元素都密切相关于同一功能且必须顺序执行，前一个功能元素的输出就是后一个功能元素的输入 顺序执行、输入为输出 功能内聚 最强的内聚，模块内所有元素共同作用完成一个功能，缺一不可 共同作用，缺一不可 耦合耦合程度从低到高如下表所示： 耦合分类 定义 记忆关键字 无直接耦合 两个模块之间没有直接的关系，它们分别从属于不同模块的控制与调用，不传递任何信息 无直接关系 数据耦合 两个模块之间有调用关系，传递的是简单的数据值，相当于高级语言中的值传递 传递数据值调用 标记耦合 两个模块之间传递的是数据结构 传递数据结构 控制耦合 一个模块调用另一个模块时，传递的是控制变量，被调用模块通过该控制变量的值，有选择的执行模块内的某一功能 控制变量，选择执行某一功能 外部耦合 模块间通过软件之外的环境联合（如I&#x2F;O将模块耦合到特定的设备，格式，通信协议）时 软件外部环境 公共耦合 通过一个公共数据环境相互作用的那些模块间的耦合 公共数据结构 内容耦合 当一个模块直接使用另一个模块的内部数据，或通过非正常入口转入另一个内部模块时 模块内部关联 系统设计系统设计的主要目的是系统制定蓝图，在各种技术和实施方法中权衡利弊，精心设计，合理的使用各种资源，得出新系统的详细设计方案。步骤：概要设计和详细设计概要设计基本任务：设计软件系统总体结构，数据结构及数据库设计，编写概要设计文档，评审。详细设计基本任务：模块内详细算法设计、模块内数据结构设计，数据库物理设计、其他设计（代码，输入输出格式，用户界面），编写详细设计文档，评审。 软件需求按需求内容分类：业务需求:由客户提出的宏观的一个功能需求。用户需求：设计员去调查需求中涉及的每个用户的具体需求。系统需求：经过整合，形成最终的系统需求，包括功能，性能，设计约束三个方面的需求。从客户角度分类：基本需求：需求明确规定的功能。期望需求：除了基本需求外，客户认为理所应当包含在内的其他功能。兴奋需求：客户未要求其他功能需求，会浪费项目开发时间和成本。软件需求分类：功能需求：软件必须完成的基本动作。性能需求：说明软件或人与软件交互的静态或动态数值需求。如系统响应速度，处理速度等。设计约束：受其他硬件标准限制等方面影响。属性：可用性、安全性、可维护性，可移植性。外部接口需求：用户接口，硬件接口，软件接口，通信接口。 测试基础知识系统测试是为了发现错误而执行程序的过程，成功的测试是发现了至今尚未发现的错误的测试。测试原则：应尽早并不断的进行测试。测试工作应该避免由开发软件的人或小组承担。在设计测试方案时，不仅要确定输入数据，而且要根据系统功能确定预期的输出结果。即包含有效、合理的测试用例，也包含不合理、失效的用例。检验程序是否做了该做的事，且是否做了不该做的事。严格按照测试计划执行。妥善保存测试用例和测试计划。测试用例可以重复使用或追加测试。 测试阶段单元测试：对单个模块进行测试，由程序员自己测试模块内部的接口、信息、功能，测试依据是软件详细说明书。在单元测试中，驱动模块（上层）用来调用被测模块，自顶向下的单元测试中不需要另外编写驱动模块，桩模块（底层）用来模拟被测模块所调用的子模块。集成测试：将模块组合起来进行测试，分为一次性组装（简单，节约时间，发现错误少，只适合小项目）和增量式组装（能够发现更多错误，耗时长，又可分为：自顶向下，自底向上，混合式）。确认测试：对已完成的软件进行功能上的测试，分为内部确认测试（无用户情况）、Alpha测试（用户在开发环境下测试），Beat测试（用户在实际使用时进行的测试）、验收测试（用户根据SRS对项目进行验收）。系统测试：对软甲进行性能测试，主要分为三个方面，即负载测试（在极限情况下，系统各项性能指标）、强度测试（系统资源特别低的情况下），容量测试（并发测试，系统可以处理的同时在线的最大用户数）。其他还有可靠性等性能测试，系统测试一般使用黑盒测试方法。回归测试：软件修改错误或者变更后，进行回归测试以验证之前正确的代码是否引入了错误。动态测试：程序运行时测试，分为：黑盒测试法：功能性测试，不了解软件代码结构，根据功能设计用例，测试软件功能。白盒测试法：结构性测试，明确代码流程，根据代码逻辑设计用例，进行用例覆盖。灰盒测试法：即既有黑盒测试，也有白盒测试。静态测试：程序静止时测试，即対代码进行人工审查，分为：桌前检查：程序员检查自己编写的程序，在程序编译后，单元测试前。代码审查：由若干个程序员和测试人员组成评审小组，通过召开程序评审会来进行审查。代码走查：也是采用开会来对代码进行审查，但并非简单的审查代码，而是由测试人员提供用例，让程序员扮演计算机的角色，手动运行测试用例，检查代码逻辑。 测试策略自底向上：从最底层模块开始测试，需要编写驱动程序，而后开始逐一合并模块，最终完成整个系统的测试。优点是较早的验证了底层模块。自顶向下：先测试整个系统，需要编写桩程序，而后逐步向下直至最后测试最低层模块。优点是较早的验证了系统的主要控制和判断点。三明治：既有自底向上也有自顶向下的测试方法，二者都包括。兼有二者的优点，缺点是测试工作量大。 测试用例设计黑盒测试用例：将程序看做一个黑盒子，只知道输入输出，不知道内部代码，由此设计出测试用例，分为下面几类：等价类划分：把所有的数据按照某种特性进行归类，而后在每类的数据里选取一个即可。等价类测试用例的设计原则：设计一个新的测试用例，使其尽可能多的覆盖尚未被覆盖的有效等价类，重复这一步，直到所有的有效等价类都被覆盖为止；设计一个新的测试用例，使其覆盖一个尚未被覆盖的无效等价类，重复这一步，直到所有的无效等价类被覆盖为止。边界值划分：将每类的边界值作为测试用例，边界值一般为范围的两断值以及在此范围之外的与此范围间隔最小的两个值，如年龄范围0-150，边界值为0,150，1,151四个。白盒测试用例：知道程序的代码逻辑，按照程序的代码语句，来设计覆盖代码分支的测试用例，覆盖级别从低至高分为下面六种：1.语句覆盖：逻辑代码中所有的语句都要执行一遍，覆盖层级最低，因为执行了所有语句，不代表执行了所有条件判断。2. 判定覆盖：逻辑代码中所有判断语句的条件的真假分支都要覆盖一次。3. 条件覆盖：对于代码中的一个条件，可能是组合的，如a&gt;0&amp;&amp;b&lt;0，判断覆盖只针对此组合条件的真假分支做两个测试用例，而条件覆盖是对每个独立的条件都要做真假分支的测试用例，共可有4个测试用例，层级更高，注意区别，条件覆盖，针对每个条件都要真假覆盖，判定覆盖，只针对一个条件判断语句。4. 判定&#x2F;条件覆盖：使判定中每个条件的所有可能取值（真&#x2F;假）至少出现一次，并且每个判定本身的判定结果（真&#x2F;假）也至少出现一次，即两种覆盖的综合。5. 条件组合覆盖：每个判定条件中条件的各个可能值的组合都至少出现一次。 6. 路径覆盖：逻辑代码中所有可行路径都覆盖了，覆盖层级最高。 八 标准化知识产权保护期限 单位和个人的著作权归属 单位和委托的区别当合同中未规定著作权的归属时，著作权默认归于单位，而在委托创作中，著作权默认归属创作方个人，具体如下： 侵权判定中国公民、法人、或其他组织的作品，无论是否发表，都享有著作权。开发软件所用的思想、处理过程、操作方法或者数学概念不受保护。著作权法不适用下列情形：法律、法规、国家机关的决议、决定、命令和其他具有立法、行政、司法性质的文件及官方正式译文。时事新闻。立法，通用数表，通用表格和公式。 其他法律细则商业秘密构成条件：未公开，能权利人带来利益，保密性。商业秘密无固定保密时间，一般由企业自行决定。且不能延长。 专利权期限：发明专利权保护期限为自申请日起20年，实用新型专利权和外观设计专利权保护期限为申请日起10年。专利权谁先申请就归谁，若同一天申请，则双方协商或者以抽签的方式决定。 商标权必须使用注册商标的商品范围包括：国家规定并由国家工商行政管理局公布的人用药物和烟草制品、国家规定并由国家工商行政管理局公布的其他作品。商标权认定方式与专利权类似，也是谁先申请就归谁，如果同一天申请，则谁先使用归谁，若都未使用或同时使用，则由双方协商或者一抽签的方式决定。“近似商标”是指文字、数字、图形、三维标志或者颜色组合等商标的构成要素的发音、视觉、含义或排列顺序及整体结构上虽有一定区别，但又使人难以区分，容易产生混淆的商标。会产生商标侵权，故不能同时注册，由双方协商决定，若协商未果后采用抽签决定。 引用资料只能引用发表的作品，不能引用未发表的作品；只能限于介绍、评论作品，只要不构成自己作品的主要成分，可适当引用资料，不必征得原作者的同意，不需要向他支付报酬。","categories":[{"name":"软考","slug":"软考","permalink":"http://blog.b6123.top/categories/%E8%BD%AF%E8%80%83/"}],"tags":[{"name":"软考","slug":"软考","permalink":"http://blog.b6123.top/tags/%E8%BD%AF%E8%80%83/"}]},{"title":"线程池精讲","slug":"xccjj","date":"2022-11-01T03:05:02.000Z","updated":"2022-11-01T05:46:28.489Z","comments":true,"path":"2022/11/01/xccjj/","link":"","permalink":"http://blog.b6123.top/2022/11/01/xccjj/","excerpt":"","text":"什么是线程池为了避免重复的创建线程 线程池的出现可以让线程复用 通俗的讲 当有任务来的时候 就会像线程池里面拿一个线程 当工作完成后 不是关闭线程 而是归还线程到线程池中这样避免了重复开销 这样就会节省性能和时间 线程池的核心讲解核心参数corePoolsize : 线程中允许的核心线程数maximumPoolsize : 该线程所允许的最大线程数keepAliveTime : 空余线程的存活时间并不会对所有的线程起作用 如果线程数大于corePoolsize 那么这些线程就不会因为被空闲太久而关闭 除非你调用 allowcorethreadtimeout 方法 这个方法可以使核心线程数也被回收只有当线程池中的线程数大于corePoolSize时keepAliveTime才会起作用,知道线程中的线程数不大于corepoolSIze,unit : 时间单位workQueue : 阻塞队列 在此的作用就是用来存放线程threadFatory: 线程工厂 可以为线程池创建新线程defaultHnadler: 拒绝策略 当线程失败等 如何处理方式 常见的四种线程池1.FixedThreadPool 有固定的线程池 其中corePoolSize &#x3D; maxinumPoolSize 且keepalivetime 为0 适合线程稳定的场所2.singleThreadPool 固定数量的线程池且数量为1 corePoolSize &#x3D; maxinumPoolSize&#x3D; 1 keepaliveTime &#x3D;03.cachedThreadPool corePoolSize&#x3D;0 maxiumPoolSize 不停的创建线程4.ScheduledThreadPool 具有定期执行任务功能的线程池 阻塞队列一览 workQueue1.数组阻塞队列 ArrayBlockingQueue 对应线程池队列：有界的任务队列可以使用ArrayBlockingQueue实现。当使用有界队列时，若有新的任务需要执行，如果线程池的实际线程数小于corePoolSize， 则会优先创建新的线程，若大于corePoolSize，则会将新任务假如等待队列。 若等待队列已满，无法加入，在总线程数，不大于maximumPoolSize的前提下，创建新的进程执行任务。若大于maximumPoolSize，则执行拒绝策略。2.延迟队列DelayQueue 3.链阻塞队列 LinkedBlockingQueue 对应线程池队列：无界的任务队列可以通过LinkedBlockingQueue类实现。与有界队列相反，除非系统资源耗尽，否则无界的任务队列不存在任务入队失败的情况。 当有新的任务到来，系统的线程数小于corePoolSize时，线程池会产生新的线程执行任务，但当系统的线程数达到corePoolSize后，就会继续增加。 若后续仍有新的任务假如，而又没有空闲的线程资源，则任务直接进入对列等待。若任务创建和处理的速度差异很大，无界队列会保持快速增长，直到耗尽系统内存。 3.同步队列 SynchronousQueue SynchronousQueue经常用来,一端或者双端严格遵守”单工”(单工作者)模式的场景,队列的两个操作端分别是productor和consumer.常用于一个productor多个consumer的场景。在ThreadPoolExecutor中,通过Executors创建的cachedThreadPool就是使用此类型队列.已确保,如果现有线程无法接收任务(offer失败),将会创建新的线程来执行.拒绝策略等待队列也已经排满了,再也塞不下新的任务了同时,线程池的max也到达了,无法接续为新任务服务这时我们需要拒绝策略机制合理的处理这个问题.AbortPolicy:直接抛出异常组织系统正常工作CallerRunPolicy：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务DiscardOldestPolicy：丢弃最老的一个请隶，尝试再次提交当前任务DiscardPolicy:直接丢弃任务不予处理也不抛出异常，这是最好的拒绝策略如果需要自定义拒绝簽略可以实现RejectdExceutionHandler接口已上的内置策略均实现了rejectExcutionHandler接口 线程池运行流程 1.在创建线程池后 等待提交过来的任务请求 2.当调用execute()方法添加一个请求任务时线程池会做如下判断： ① 如果正在运行线程数量小于corePoolSize 那么马上创建线程运行这个任务② 如果正在运行的线程数量大于或者等于corePoolSize 那么将任务放入队列③ 如果这时候队列满了且正在运行的线程数量还小于maximumPoolSize 那么还是要创建非核心线程来立刻运行这个任务④ 如果队列满了且正在运行的线程数量大于或者等于maximumPoolSize 那么线程池会启动饱和拒绝策略来执行 3.当一个线程完成任务时 他会从队列中取下一个任务4.当一个线程无事可做超过一定时间keepAliveTime 时 线程池会判断： 如果当前运行的线程大于corePoolSize那么这个线程就会被停掉线程池在生产中选择哪种1.在生产中我们JDK自带的线程池 一个不用 我们需要自己创建线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。 说明：使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题2.线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors返回的线程池对象的弊端如下：1）FixedThreadPool和SingleThreadPool:允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。2）CachedThreadPool和ScheduledThreadPool:允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。 如何合理的配置线程池分为cpu密集型和io密集型 cpu密集型的意思就是该任务需要大量的计算 而没有阻塞 cpu一直全速运行 CPU密集型任务只有在真正的多核CPU上才能得到加速而在真正的cpu上 无论你开你个线程模拟该任务都不可能得到加速 因为cpu运算能力就那些cpu 密集型任务配置尽可能少的线程数量 一般公式cpu+1个线程的线程池io密集型由于io密集型任务线程并不是一直在执行 则应配置尽可能多的线程 如cpu*2io密集型 即该任务需要大量io 及大量的阻塞在单线程上运行IO密集型的任务会导致大量的cpu运算能力浪费在等待所以在IO密集型任务中使用多线程可以大大的加速程序运行 即使在单核CPU上 这种加速主要是为了利用被浪费掉阻塞时间IO密集型 大部分线程都阻塞 故需要多配置线程参考公式 CPU核数&#x2F;1 -阻塞系数 阻塞系数在0。8-0.9之间比如 8核cpu: 8&#x2F;1-0.9 &#x3D; 80个线程数corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子：假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；当10个工人都有任务在做时，如果还来了任务，就把任务进行排队等待；如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招4个临时工人进来；然后就将任务也分配给这4个临时工人做；如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系","categories":[{"name":"多线程","slug":"多线程","permalink":"http://blog.b6123.top/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"JAVA源码","slug":"JAVA源码","permalink":"http://blog.b6123.top/tags/JAVA%E6%BA%90%E7%A0%81/"}]},{"title":"学习 Vue，从入门到放弃","slug":"newpapername","date":"2022-11-01T02:46:06.330Z","updated":"2022-11-01T02:46:06.330Z","comments":true,"path":"2022/11/01/newpapername/","link":"","permalink":"http://blog.b6123.top/2022/11/01/newpapername/","excerpt":"","text":"在 2016 年学 JavaScript 是一种什么样的体验？因为之前开发用的版本较低，而学习Vue用的较新版本，本地webpack和node肯定都过时了，为了避免与原有项目冲突，还又安装了虚拟机，然后安装开发环境，vscode是不能少的~~虽然学的有点累，但是不想放弃，希望大家留言讨论下正确的学习Vue 姿势 （从哪里开始，从哪里进阶，多长时间可以玩转项目）感觉官网有点像词典 ㄒoㄒ，最好是有阮一峰老师那种风格的 生活不止眼前的苟且，还有诗和远方~~ 原文地址：https://www.cnblogs.com/jying/p/11203138.html作者：一定会去旅行 欢迎任何形式的转载，但请务必在文章开始位置使用明显加粗字体注明出处。 限于本人水平，如果文章和代码有表述不当之处，还请不吝赐教。","categories":[{"name":"vue","slug":"vue","permalink":"http://blog.b6123.top/categories/vue/"}],"tags":[{"name":"vue","slug":"vue","permalink":"http://blog.b6123.top/tags/vue/"}]},{"title":"Sentinel源码分析","slug":"sentinel","date":"2022-11-01T02:46:06.330Z","updated":"2022-11-01T02:46:06.330Z","comments":true,"path":"2022/11/01/sentinel/","link":"","permalink":"http://blog.b6123.top/2022/11/01/sentinel/","excerpt":"","text":"1.Sentinel的基本概念Sentinel实现限流、隔离、降级、熔断等功能，本质要做的就是两件事情： 统计数据：统计某个资源的访问数据（QPS、RT等信息） 规则判断：判断限流规则、隔离规则、降级规则、熔断规则是否满足 这里的资源就是希望被Sentinel保护的业务，例如项目中定义的controller方法就是默认被Sentinel保护的资源。 1.1.ProcessorSlotChain实现上述功能的核心骨架是一个叫做ProcessorSlotChain的类。这个类基于责任链模式来设计，将不同的功能（限流、降级、系统保护）封装为一个个的Slot，请求进入后逐个执行即可。 其工作流如图： 责任链中的Slot也分为两大类： 统计数据构建部分（statistic） NodeSelectorSlot：负责构建簇点链路中的节点（DefaultNode），将这些节点形成链路树 ClusterBuilderSlot：负责构建某个资源的ClusterNode，ClusterNode可以保存资源的运行信息（响应时间、QPS、block 数目、线程数、异常数等）以及来源信息（origin名称） StatisticSlot：负责统计实时调用数据，包括运行信息、来源信息等 规则判断部分（rule checking） AuthoritySlot：负责授权规则（来源控制） SystemSlot：负责系统保护规则 ParamFlowSlot：负责热点参数限流规则 FlowSlot：负责限流规则 DegradeSlot：负责降级规则 1.2.NodeSentinel中的簇点链路是由一个个的Node组成的，Node是一个接口，包括下面的实现： 所有的节点都可以记录对资源的访问统计数据，所以都是StatisticNode的子类。 按照作用分为两类Node： DefaultNode：代表链路树中的每一个资源，一个资源出现在不同链路中时，会创建不同的DefaultNode节点。而树的入口节点叫EntranceNode，是一种特殊的DefaultNode ClusterNode：代表资源，一个资源不管出现在多少链路中，只会有一个ClusterNode。记录的是当前资源被访问的所有统计数据之和。 DefaultNode记录的是资源在当前链路中的访问数据，用来实现基于链路模式的限流规则。ClusterNode记录的是资源在所有链路中的访问数据，实现默认模式、关联模式的限流规则。 例如：我们在一个SpringMVC项目中，有两个业务： 业务1：controller中的资源/order/query访问了service中的资源/goods 业务2：controller中的资源/order/save访问了service中的资源/goods 创建的链路图如下： 1.3.Entry默认情况下，Sentinel会将controller中的方法作为被保护资源，那么问题来了，我们该如何将自己的一段代码标记为一个Sentinel的资源呢？ Sentinel中的资源用Entry来表示。声明Entry的API示例： // 资源名可使用任意有业务语义的字符串，比如方法名、接口名或其它可唯一标识的字符串。 try (Entry entry = SphU.entry(\"resourceName\")) &#123; // 被保护的业务逻辑 // do something here... &#125; catch (BlockException ex) &#123; // 资源访问阻止，被限流或被降级 // 在此处进行相应的处理操作 &#125; 1.3.1.自定义资源例如，我们在order-service服务中，将OrderService的queryOrderById()方法标记为一个资源。 1）首先在order-service中引入sentinel依赖 &lt;!--sentinel--> &lt;dependency> &lt;groupId>com.alibaba.cloud&lt;/groupId> &lt;artifactId>spring-cloud-starter-alibaba-sentinel&lt;/artifactId> &lt;/dependency> 2）然后配置Sentinel地址 spring: cloud: sentinel: transport: dashboard: localhost:8089 # 这里我的sentinel用了8089的端口 3）修改OrderService类的queryOrderById方法 代码这样来实现： public Order queryOrderById(Long orderId) &#123; // 创建Entry，标记资源，资源名为resource1 try (Entry entry = SphU.entry(\"resource1\")) &#123; // 1.查询订单，这里是假数据 Order order = Order.build(101L, 4999L, \"小米 MIX4\", 1, 1L, null); // 2.查询用户，基于Feign的远程调用 User user = userClient.findById(order.getUserId()); // 3.设置 order.setUser(user); // 4.返回 return order; &#125;catch (BlockException e)&#123; log.error(\"被限流或降级\", e); return null; &#125; &#125; 4）访问 打开浏览器，访问order服务：http://localhost:8080/order/101 然后打开sentinel控制台，查看簇点链路： 1.3.2.基于注解标记资源在之前学习Sentinel的时候，我们知道可以通过给方法添加@SentinelResource注解的形式来标记资源。 这个是怎么实现的呢？ 来看下我们引入的Sentinel依赖包： 其中的spring.factories声明需要就是自动装配的配置类，内容如下： 我们来看下SentinelAutoConfiguration这个类： 可以看到，在这里声明了一个Bean，SentinelResourceAspect： /** * Aspect for methods with &#123;@link SentinelResource&#125; annotation. * * @author Eric Zhao */ @Aspect public class SentinelResourceAspect extends AbstractSentinelAspectSupport &#123; // 切点是添加了 @SentinelResource注解的类 @Pointcut(\"@annotation(com.alibaba.csp.sentinel.annotation.SentinelResource)\") public void sentinelResourceAnnotationPointcut() &#123; &#125; // 环绕增强 @Around(\"sentinelResourceAnnotationPointcut()\") public Object invokeResourceWithSentinel(ProceedingJoinPoint pjp) throws Throwable &#123; // 获取受保护的方法 Method originMethod = resolveMethod(pjp); // 获取 @SentinelResource注解 SentinelResource annotation = originMethod.getAnnotation(SentinelResource.class); if (annotation == null) &#123; // Should not go through here. throw new IllegalStateException(\"Wrong state for SentinelResource annotation\"); &#125; // 获取注解上的资源名称 String resourceName = getResourceName(annotation.value(), originMethod); EntryType entryType = annotation.entryType(); int resourceType = annotation.resourceType(); Entry entry = null; try &#123; // 创建资源 Entry entry = SphU.entry(resourceName, resourceType, entryType, pjp.getArgs()); // 执行受保护的方法 Object result = pjp.proceed(); return result; &#125; catch (BlockException ex) &#123; return handleBlockException(pjp, annotation, ex); &#125; catch (Throwable ex) &#123; Class&lt;? extends Throwable>[] exceptionsToIgnore = annotation.exceptionsToIgnore(); // The ignore list will be checked first. if (exceptionsToIgnore.length > 0 &amp;&amp; exceptionBelongsTo(ex, exceptionsToIgnore)) &#123; throw ex; &#125; if (exceptionBelongsTo(ex, annotation.exceptionsToTrace())) &#123; traceException(ex); return handleFallback(pjp, annotation, ex); &#125; // No fallback function can handle the exception, so throw it out. throw ex; &#125; finally &#123; if (entry != null) &#123; entry.exit(1, pjp.getArgs()); &#125; &#125; &#125; &#125; 简单来说，@SentinelResource注解就是一个标记，而Sentinel基于AOP思想，对被标记的方法做环绕增强，完成资源（Entry）的创建。 1.4.Context上一节，我们发现簇点链路中除了controller方法、service方法两个资源外，还多了一个默认的入口节点： sentinel_spring_web_context，是一个EntranceNode类型的节点 这个节点是在初始化Context的时候由Sentinel帮我们创建的。 1.4.1.什么是Context那么，什么是Context呢？ Context 代表调用链路上下文，贯穿一次调用链路中的所有资源（ Entry），基于ThreadLocal。 Context 维持着入口节点（entranceNode）、本次调用链路的 curNode（当前资源节点）、调用来源（origin）等信息。 后续的Slot都可以通过Context拿到DefaultNode或者ClusterNode，从而获取统计数据，完成规则判断 Context初始化的过程中，会创建EntranceNode，contextName就是EntranceNode的名称 对应的API如下： // 创建context，包含两个参数：context名称、 来源名称 ContextUtil.enter(\"contextName\", \"originName\"); 1.4.2.Context的初始化那么这个Context又是在何时完成初始化的呢？ 1.4.2.1.自动装配来看下我们引入的Sentinel依赖包： 其中的spring.factories声明需要就是自动装配的配置类，内容如下： 我们先看SentinelWebAutoConfiguration这个类： 这个类实现了WebMvcConfigurer，我们知道这个是SpringMVC自定义配置用到的类，可以配置HandlerInterceptor： 可以看到这里配置了一个SentinelWebInterceptor的拦截器。 SentinelWebInterceptor的声明如下： 发现它继承了AbstractSentinelInterceptor这个类。 HandlerInterceptor拦截器会拦截一切进入controller的方法，执行preHandle前置拦截方法，而Context的初始化就是在这里完成的。 1.4.2.2.AbstractSentinelInterceptorHandlerInterceptor拦截器会拦截一切进入controller的方法，执行preHandle前置拦截方法，而Context的初始化就是在这里完成的。 我们来看看这个类的preHandle实现： @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; try &#123; // 获取资源名称，一般是controller方法的@RequestMapping路径，例如/order/&#123;orderId&#125; String resourceName = getResourceName(request); if (StringUtil.isEmpty(resourceName)) &#123; return true; &#125; // 从request中获取请求来源，将来做 授权规则 判断时会用 String origin = parseOrigin(request); // 获取 contextName，默认是sentinel_spring_web_context String contextName = getContextName(request); // 创建 Context ContextUtil.enter(contextName, origin); // 创建资源，名称就是当前请求的controller方法的映射路径 Entry entry = SphU.entry(resourceName, ResourceTypeConstants.COMMON_WEB, EntryType.IN); request.setAttribute(baseWebMvcConfig.getRequestAttributeName(), entry); return true; &#125; catch (BlockException e) &#123; try &#123; handleBlockException(request, response, e); &#125; finally &#123; ContextUtil.exit(); &#125; return false; &#125; &#125; 1.4.2.3.ContextUtil创建Context的方法就是 ContextUtil.enter(contextName, origin); 我们进入该方法： public static Context enter(String name, String origin) &#123; if (Constants.CONTEXT_DEFAULT_NAME.equals(name)) &#123; throw new ContextNameDefineException( \"The \" + Constants.CONTEXT_DEFAULT_NAME + \" can't be permit to defined!\"); &#125; return trueEnter(name, origin); &#125; 进入trueEnter方法： protected static Context trueEnter(String name, String origin) &#123; // 尝试获取context Context context = contextHolder.get(); // 判空 if (context == null) &#123; // 如果为空，开始初始化 Map&lt;String, DefaultNode> localCacheNameMap = contextNameNodeMap; // 尝试获取入口节点 DefaultNode node = localCacheNameMap.get(name); if (node == null) &#123; LOCK.lock(); try &#123; node = contextNameNodeMap.get(name); if (node == null) &#123; // 入口节点为空，初始化入口节点 EntranceNode node = new EntranceNode(new StringResourceWrapper(name, EntryType.IN), null); // 添加入口节点到 ROOT Constants.ROOT.addChild(node); // 将入口节点放入缓存 Map&lt;String, DefaultNode> newMap = new HashMap&lt;>(contextNameNodeMap.size() + 1); newMap.putAll(contextNameNodeMap); newMap.put(name, node); contextNameNodeMap = newMap; &#125; &#125; finally &#123; LOCK.unlock(); &#125; &#125; // 创建Context，参数为：入口节点 和 contextName context = new Context(node, name); // 设置请求来源 origin context.setOrigin(origin); // 放入ThreadLocal contextHolder.set(context); &#125; // 返回 return context; &#125; 2.ProcessorSlotChain执行流程接下来我们跟踪源码，验证下ProcessorSlotChain的执行流程。 2.1.入口首先，回到一切的入口，AbstractSentinelInterceptor类的preHandle方法： 还有，SentinelResourceAspect的环绕增强方法： 可以看到，任何一个资源必定要执行SphU.entry()这个方法: public static Entry entry(String name, int resourceType, EntryType trafficType, Object[] args) throws BlockException &#123; return Env.sph.entryWithType(name, resourceType, trafficType, 1, args); &#125; 继续进入Env.sph.entryWithType(name, resourceType, trafficType, 1, args);： @Override public Entry entryWithType(String name, int resourceType, EntryType entryType, int count, boolean prioritized, Object[] args) throws BlockException &#123; // 将 资源名称等基本信息 封装为一个 StringResourceWrapper对象 StringResourceWrapper resource = new StringResourceWrapper(name, entryType, resourceType); // 继续 return entryWithPriority(resource, count, prioritized, args); &#125; 进入entryWithPriority方法： private Entry entryWithPriority(ResourceWrapper resourceWrapper, int count, boolean prioritized, Object... args) throws BlockException &#123; // 获取 Context Context context = ContextUtil.getContext(); if (context == null) &#123; // Using default context. context = InternalContextUtil.internalEnter(Constants.CONTEXT_DEFAULT_NAME); &#125; 、 // 获取 Slot执行链，同一个资源，会创建一个执行链，放入缓存 ProcessorSlot&lt;Object> chain = lookProcessChain(resourceWrapper); // 创建 Entry，并将 resource、chain、context 记录在 Entry中 Entry e = new CtEntry(resourceWrapper, chain, context); try &#123; // 执行 slotChain chain.entry(context, resourceWrapper, null, count, prioritized, args); &#125; catch (BlockException e1) &#123; e.exit(count, args); throw e1; &#125; catch (Throwable e1) &#123; // This should not happen, unless there are errors existing in Sentinel internal. RecordLog.info(\"Sentinel unexpected exception\", e1); &#125; return e; &#125; 在这段代码中，会获取ProcessorSlotChain对象，然后基于chain.entry()开始执行slotChain中的每一个Slot. 而这里创建的是其实现类：DefaultProcessorSlotChain. 获取ProcessorSlotChain以后会保存到一个Map中，key是ResourceWrapper，值是ProcessorSlotChain. 所以，一个资源只会有一个ProcessorSlotChain. 2.2.DefaultProcessorSlotChain我们进入DefaultProcessorSlotChain的entry方法： @Override public void entry(Context context, ResourceWrapper resourceWrapper, Object t, int count, boolean prioritized, Object... args) throws Throwable &#123; // first，就是责任链中的第一个 slot first.transformEntry(context, resourceWrapper, t, count, prioritized, args); &#125; 这里的first，类型是AbstractLinkedProcessorSlot： 看下继承关系： 因此，first一定是这些实现类中的一个，按照最早讲的责任链顺序，first应该就是 NodeSelectorSlot。 不过，既然是基于责任链模式，所以这里只要记住下一个slot就可以了，也就是next： next确实是NodeSelectSlot类型。 而NodeSelectSlot的next一定是ClusterBuilderSlot，依次类推： 责任链就建立起来了。 2.3.NodeSelectorSlotNodeSelectorSlot负责构建簇点链路中的节点（DefaultNode），将这些节点形成链路树。 核心代码： @Override public void entry(Context context, ResourceWrapper resourceWrapper, Object obj, int count, boolean prioritized, Object... args) throws Throwable &#123; // 尝试获取 当前资源的 DefaultNode DefaultNode node = map.get(context.getName()); if (node == null) &#123; synchronized (this) &#123; node = map.get(context.getName()); if (node == null) &#123; // 如果为空，为当前资源创建一个新的 DefaultNode node = new DefaultNode(resourceWrapper, null); HashMap&lt;String, DefaultNode> cacheMap = new HashMap&lt;String, DefaultNode>(map.size()); cacheMap.putAll(map); // 放入缓存中，注意这里的 key是contextName， // 这样不同链路进入相同资源，就会创建多个 DefaultNode cacheMap.put(context.getName(), node); map = cacheMap; // 当前节点加入上一节点的 child中，这样就构成了调用链路树 ((DefaultNode) context.getLastNode()).addChild(node); &#125; &#125; &#125; // context中的curNode（当前节点）设置为新的 node context.setCurNode(node); // 执行下一个 slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; 这个Slot完成了这么几件事情： 为当前资源创建 DefaultNode 将DefaultNode放入缓存中，key是contextName，这样不同链路入口的请求，将会创建多个DefaultNode，相同链路则只有一个DefaultNode 将当前资源的DefaultNode设置为上一个资源的childNode 将当前资源的DefaultNode设置为Context中的curNode（当前节点） 下一个slot，就是ClusterBuilderSlot 2.4.ClusterBuilderSlotClusterBuilderSlot负责构建某个资源的ClusterNode，核心代码： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // 判空，注意ClusterNode是共享的成员变量，也就是说一个资源只有一个ClusterNode，与链路无关 if (clusterNode == null) &#123; synchronized (lock) &#123; if (clusterNode == null) &#123; // 创建 cluster node. clusterNode = new ClusterNode(resourceWrapper.getName(), resourceWrapper.getResourceType()); HashMap&lt;ResourceWrapper, ClusterNode> newMap = new HashMap&lt;>(Math.max(clusterNodeMap.size(), 16)); newMap.putAll(clusterNodeMap); // 放入缓存，可以是nodeId，也就是resource名称 newMap.put(node.getId(), clusterNode); clusterNodeMap = newMap; &#125; &#125; &#125; // 将资源的 DefaultNode与 ClusterNode关联 node.setClusterNode(clusterNode); // 记录请求来源 origin 将 origin放入 entry if (!\"\".equals(context.getOrigin())) &#123; Node originNode = node.getClusterNode().getOrCreateOriginNode(context.getOrigin()); context.getCurEntry().setOriginNode(originNode); &#125; // 继续下一个slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; 2.5.StatisticSlotStatisticSlot负责统计实时调用数据，包括运行信息（访问次数、线程数）、来源信息等。 StatisticSlot是实现限流的关键，其中基于滑动时间窗口算法维护了计数器，统计进入某个资源的请求次数。 核心代码： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; try &#123; // 放行到下一个 slot，做限流、降级等判断 fireEntry(context, resourceWrapper, node, count, prioritized, args); // 请求通过了, 线程计数器 +1 ，用作线程隔离 node.increaseThreadNum(); // 请求计数器 +1 用作限流 node.addPassRequest(count); if (context.getCurEntry().getOriginNode() != null) &#123; // 如果有 origin，来源计数器也都要 +1 context.getCurEntry().getOriginNode().increaseThreadNum(); context.getCurEntry().getOriginNode().addPassRequest(count); &#125; if (resourceWrapper.getEntryType() == EntryType.IN) &#123; // 如果是入口资源，还要给全局计数器 +1. Constants.ENTRY_NODE.increaseThreadNum(); Constants.ENTRY_NODE.addPassRequest(count); &#125; // 请求通过后的回调. for (ProcessorSlotEntryCallback&lt;DefaultNode> handler : StatisticSlotCallbackRegistry.getEntryCallbacks()) &#123; handler.onPass(context, resourceWrapper, node, count, args); &#125; &#125; catch (Throwable e) &#123; // 各种异常处理就省略了。。。 context.getCurEntry().setError(e); throw e; &#125; &#125; 另外，需要注意的是，所有的计数+1动作都包括两部分，以 node.addPassRequest(count);为例： @Override public void addPassRequest(int count) &#123; // DefaultNode的计数器，代表当前链路的 计数器 super.addPassRequest(count); // ClusterNode计数器，代表当前资源的 总计数器 this.clusterNode.addPassRequest(count); &#125; 具体计数方式，我们后续再看。 接下来，进入规则校验的相关slot了，依次是： AuthoritySlot：负责授权规则（来源控制） SystemSlot：负责系统保护规则 ParamFlowSlot：负责热点参数限流规则 FlowSlot：负责限流规则 DegradeSlot：负责降级规则 2.6.AuthoritySlot负责请求来源origin的授权规则判断，如图： 核心API： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // 校验黑白名单 checkBlackWhiteAuthority(resourceWrapper, context); // 进入下一个 slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; 黑白名单校验的逻辑： void checkBlackWhiteAuthority(ResourceWrapper resource, Context context) throws AuthorityException &#123; // 获取授权规则 Map&lt;String, Set&lt;AuthorityRule>> authorityRules = AuthorityRuleManager.getAuthorityRules(); if (authorityRules == null) &#123; return; &#125; Set&lt;AuthorityRule> rules = authorityRules.get(resource.getName()); if (rules == null) &#123; return; &#125; // 遍历规则并判断 for (AuthorityRule rule : rules) &#123; if (!AuthorityRuleChecker.passCheck(rule, context)) &#123; // 规则不通过，直接抛出异常 throw new AuthorityException(context.getOrigin(), rule); &#125; &#125; &#125; 再看下AuthorityRuleChecker.passCheck(rule, context)方法： static boolean passCheck(AuthorityRule rule, Context context) &#123; // 得到请求来源 origin String requester = context.getOrigin(); // 来源为空，或者规则为空，都直接放行 if (StringUtil.isEmpty(requester) || StringUtil.isEmpty(rule.getLimitApp())) &#123; return true; &#125; // rule.getLimitApp()得到的就是 白名单 或 黑名单 的字符串，这里先用 indexOf方法判断 int pos = rule.getLimitApp().indexOf(requester); boolean contain = pos > -1; if (contain) &#123; // 如果包含 origin，还要进一步做精确判断，把名单列表以\",\"分割，逐个判断 boolean exactlyMatch = false; String[] appArray = rule.getLimitApp().split(\",\"); for (String app : appArray) &#123; if (requester.equals(app)) &#123; exactlyMatch = true; break; &#125; &#125; contain = exactlyMatch; &#125; // 如果是黑名单，并且包含origin，则返回false int strategy = rule.getStrategy(); if (strategy == RuleConstant.AUTHORITY_BLACK &amp;&amp; contain) &#123; return false; &#125; // 如果是白名单，并且不包含origin，则返回false if (strategy == RuleConstant.AUTHORITY_WHITE &amp;&amp; !contain) &#123; return false; &#125; // 其它情况返回true return true; &#125; 2.7.SystemSlotSystemSlot是对系统保护的规则校验： 核心API： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count,boolean prioritized, Object... args) throws Throwable &#123; // 系统规则校验 SystemRuleManager.checkSystem(resourceWrapper); // 进入下一个 slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; 来看下SystemRuleManager.checkSystem(resourceWrapper);的代码： public static void checkSystem(ResourceWrapper resourceWrapper) throws BlockException &#123; if (resourceWrapper == null) &#123; return; &#125; // Ensure the checking switch is on. if (!checkSystemStatus.get()) &#123; return; &#125; // 只针对入口资源做校验，其它直接返回 if (resourceWrapper.getEntryType() != EntryType.IN) &#123; return; &#125; // 全局 QPS校验 double currentQps = Constants.ENTRY_NODE == null ? 0.0 : Constants.ENTRY_NODE.successQps(); if (currentQps > qps) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"qps\"); &#125; // 全局 线程数 校验 int currentThread = Constants.ENTRY_NODE == null ? 0 : Constants.ENTRY_NODE.curThreadNum(); if (currentThread > maxThread) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"thread\"); &#125; // 全局平均 RT校验 double rt = Constants.ENTRY_NODE == null ? 0 : Constants.ENTRY_NODE.avgRt(); if (rt > maxRt) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"rt\"); &#125; // 全局 系统负载 校验 if (highestSystemLoadIsSet &amp;&amp; getCurrentSystemAvgLoad() > highestSystemLoad) &#123; if (!checkBbr(currentThread)) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"load\"); &#125; &#125; // 全局 CPU使用率 校验 if (highestCpuUsageIsSet &amp;&amp; getCurrentCpuUsage() > highestCpuUsage) &#123; throw new SystemBlockException(resourceWrapper.getName(), \"cpu\"); &#125; &#125; 2.8.ParamFlowSlotParamFlowSlot就是热点参数限流，如图： 是针对进入资源的请求，针对不同的请求参数值分别统计QPS的限流方式。 这里的单机阈值，就是最大令牌数量：maxCount 这里的统计窗口时长，就是统计时长：duration 含义是每隔duration时间长度内，最多生产maxCount个令牌，上图配置的含义是每1秒钟生产2个令牌。 核心API： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // 如果没有设置热点规则，直接放行 if (!ParamFlowRuleManager.hasRules(resourceWrapper.getName())) &#123; fireEntry(context, resourceWrapper, node, count, prioritized, args); return; &#125; // 热点规则判断 checkFlow(resourceWrapper, count, args); // 进入下一个 slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; 2.8.1.令牌桶热点规则判断采用了令牌桶算法来实现参数限流，为每一个不同参数值设置令牌桶，Sentinel的令牌桶有两部分组成： 这两个Map的key都是请求的参数值，value却不同，其中： tokenCounters：用来记录剩余令牌数量 timeCounters：用来记录上一个请求的时间 当一个携带参数的请求到来后，基本判断流程是这样的： 2.9.FlowSlotFlowSlot是负责限流规则的判断，如图： 包括： 三种流控模式：直接模式、关联模式、链路模式 三种流控效果：快速失败、warm up、排队等待 三种流控模式，从底层数据统计角度，分为两类： 对进入资源的所有请求（ClusterNode）做限流统计：直接模式、关联模式 对进入资源的部分链路（DefaultNode）做限流统计：链路模式 三种流控效果，从限流算法来看，分为两类： 滑动时间窗口算法：快速失败、warm up 漏桶算法：排队等待效果 2.9.1.核心流程核心API如下： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // 限流规则检测 checkFlow(resourceWrapper, context, node, count, prioritized); // 放行 fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; checkFlow方法： void checkFlow(ResourceWrapper resource, Context context, DefaultNode node, int count, boolean prioritized) throws BlockException &#123; // checker是 FlowRuleChecker 类的一个对象 checker.checkFlow(ruleProvider, resource, context, node, count, prioritized); &#125; 跟入FlowRuleChecker： public void checkFlow(Function&lt;String, Collection&lt;FlowRule>> ruleProvider, ResourceWrapper resource,Context context, DefaultNode node, int count, boolean prioritized) throws BlockException &#123; if (ruleProvider == null || resource == null) &#123; return; &#125; // 获取当前资源的所有限流规则 Collection&lt;FlowRule> rules = ruleProvider.apply(resource.getName()); if (rules != null) &#123; for (FlowRule rule : rules) &#123; // 遍历，逐个规则做校验 if (!canPassCheck(rule, context, node, count, prioritized)) &#123; throw new FlowException(rule.getLimitApp(), rule); &#125; &#125; &#125; &#125; 这里的FlowRule就是限流规则接口，其中的几个成员变量，刚好对应表单参数： public class FlowRule extends AbstractRule &#123; /** * 阈值类型 (0: 线程, 1: QPS). */ private int grade = RuleConstant.FLOW_GRADE_QPS; /** * 阈值. */ private double count; /** * 三种限流模式. * * &#123;@link RuleConstant#STRATEGY_DIRECT&#125; 直连模式; * &#123;@link RuleConstant#STRATEGY_RELATE&#125; 关联模式; * &#123;@link RuleConstant#STRATEGY_CHAIN&#125; 链路模式. */ private int strategy = RuleConstant.STRATEGY_DIRECT; /** * 关联模式关联的资源名称. */ private String refResource; /** * 3种流控效果. * 0. 快速失败, 1. warm up, 2. 排队等待, 3. warm up + 排队等待 */ private int controlBehavior = RuleConstant.CONTROL_BEHAVIOR_DEFAULT; // 预热时长 private int warmUpPeriodSec = 10; /** * 队列最大等待时间. */ private int maxQueueingTimeMs = 500; // 。。。 略 &#125; 校验的逻辑定义在FlowRuleChecker的canPassCheck方法中： public boolean canPassCheck(/*@NonNull*/ FlowRule rule, Context context, DefaultNode node, int acquireCount, boolean prioritized) &#123; // 获取限流资源名称 String limitApp = rule.getLimitApp(); if (limitApp == null) &#123; return true; &#125; // 校验规则 return passLocalCheck(rule, context, node, acquireCount, prioritized); &#125; 进入passLocalCheck()： private static boolean passLocalCheck(FlowRule rule, Context context, DefaultNode node, int acquireCount, boolean prioritized) &#123; // 基于限流模式判断要统计的节点， // 如果是直连模式，关联模式，对ClusterNode统计，如果是链路模式，则对DefaultNode统计 Node selectedNode = selectNodeByRequesterAndStrategy(rule, context, node); if (selectedNode == null) &#123; return true; &#125; // 判断规则 return rule.getRater().canPass(selectedNode, acquireCount, prioritized); &#125; 这里对规则的判断先要通过FlowRule#getRater()获取流量控制器TrafficShapingController，然后再做限流。 而TrafficShapingController有3种实现： DefaultController：快速失败，默认的方式，基于滑动时间窗口算法 WarmUpController：预热模式，基于滑动时间窗口算法，只不过阈值是动态的 RateLimiterController：排队等待模式，基于漏桶算法 最终的限流判断都在TrafficShapingController的canPass方法中。 2.9.2.滑动时间窗口滑动时间窗口的功能分两部分来看： 一是时间区间窗口的QPS计数功能，这个是在StatisticSlot中调用的 二是对滑动窗口内的时间区间窗口QPS累加，这个是在FlowRule中调用的 先来看时间区间窗口的QPS计数功能。 2.9.2.1.时间窗口请求量统计回顾2.5章节中的StatisticSlot部分，有这样一段代码： 就是在统计通过该节点的QPS，我们跟入看看，这里进入了DefaultNode内部： 发现同时对DefaultNode和ClusterNode在做QPS统计，我们知道DefaultNode和ClusterNode都是StatisticNode的子类，这里调用addPassRequest()方法，最终都会进入StatisticNode中。 随便跟入一个： 这里有秒、分两种纬度的统计，对应两个计数器。找到对应的成员变量，可以看到： 两个计数器都是ArrayMetric类型，并且传入了两个参数： // intervalInMs：是滑动窗口的时间间隔，默认为 1 秒 // sampleCount: 时间窗口的分隔数量，默认为 2，就是把 1秒分为 2个小时间窗 public ArrayMetric(int sampleCount, int intervalInMs) &#123; this.data = new OccupiableBucketLeapArray(sampleCount, intervalInMs); &#125; 如图： 接下来，我们进入ArrayMetric类的addPass方法： @Override public void addPass(int count) &#123; // 获取当前时间所在的时间窗 WindowWrap&lt;MetricBucket> wrap = data.currentWindow(); // 计数器 +1 wrap.value().addPass(count); &#125; 那么，计数器如何知道当前所在的窗口是哪个呢？ 这里的data是一个LeapArray： LeapArray的四个属性： public abstract class LeapArray&lt;T> &#123; // 小窗口的时间长度，默认是500ms ，值 = intervalInMs / sampleCount protected int windowLengthInMs; // 滑动窗口内的 小窗口 数量，默认为 2 protected int sampleCount; // 滑动窗口的时间间隔，默认为 1000ms protected int intervalInMs; // 滑动窗口的时间间隔，单位为秒，默认为 1 private double intervalInSecond; &#125; LeapArray是一个环形数组，因为时间是无限的，数组长度不可能无限，因此数组中每一个格子放入一个时间窗（window），当数组放满后，角标归0，覆盖最初的window。 因为滑动窗口最多分成sampleCount数量的小窗口，因此数组长度只要大于sampleCount，那么最近的一个滑动窗口内的2个小窗口就永远不会被覆盖，就不用担心旧数据被覆盖的问题了。 我们跟入 data.currentWindow();方法： public WindowWrap&lt;T> currentWindow(long timeMillis) &#123; if (timeMillis &lt; 0) &#123; return null; &#125; // 计算当前时间对应的数组角标 int idx = calculateTimeIdx(timeMillis); // 计算当前时间所在窗口的开始时间. long windowStart = calculateWindowStart(timeMillis); /* * 先根据角标获取数组中保存的 oldWindow 对象，可能是旧数据，需要判断. * * (1) oldWindow 不存在, 说明是第一次，创建新 window并存入，然后返回即可 * (2) oldWindow的 starTime = 本次请求的 windowStar, 说明正是要找的窗口，直接返回. * (3) oldWindow的 starTime &lt; 本次请求的 windowStar, 说明是旧数据，需要被覆盖，创建 * 新窗口，覆盖旧窗口 */ while (true) &#123; WindowWrap&lt;T> old = array.get(idx); if (old == null) &#123; // 创建新 window WindowWrap&lt;T> window = new WindowWrap&lt;T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); // 基于CAS写入数组，避免线程安全问题 if (array.compareAndSet(idx, null, window)) &#123; // 写入成功，返回新的 window return window; &#125; else &#123; // 写入失败，说明有并发更新，等待其它人更新完成即可 Thread.yield(); &#125; &#125; else if (windowStart == old.windowStart()) &#123; return old; &#125; else if (windowStart > old.windowStart()) &#123; if (updateLock.tryLock()) &#123; try &#123; // 获取并发锁，覆盖旧窗口并返回 return resetWindowTo(old, windowStart); &#125; finally &#123; updateLock.unlock(); &#125; &#125; else &#123; // 获取锁失败，等待其它线程处理就可以了 Thread.yield(); &#125; &#125; else if (windowStart &lt; old.windowStart()) &#123; // 这种情况不应该存在，写这里只是以防万一。 return new WindowWrap&lt;T>(windowLengthInMs, windowStart, newEmptyBucket(timeMillis)); &#125; &#125; &#125; 找到当前时间所在窗口（WindowWrap）后，只要调用WindowWrap对象中的add方法，计数器+1即可。 这里只负责统计每个窗口的请求量，不负责拦截。限流拦截要看FlowSlot中的逻辑。 2.9.2.2.滑动窗口QPS计算在2.9.1小节我们讲过，FlowSlot的限流判断最终都由TrafficShapingController接口中的canPass方法来实现。该接口有三个实现类： DefaultController：快速失败，默认的方式，基于滑动时间窗口算法 WarmUpController：预热模式，基于滑动时间窗口算法，只不过阈值是动态的 RateLimiterController：排队等待模式，基于漏桶算法 因此，我们跟入默认的DefaultController中的canPass方法来分析： @Override public boolean canPass(Node node, int acquireCount, boolean prioritized) &#123; // 计算目前为止滑动窗口内已经存在的请求量 int curCount = avgUsedTokens(node); // 判断：已使用请求量 + 需要的请求量（1） 是否大于 窗口的请求阈值 if (curCount + acquireCount > count) &#123; // 大于，说明超出阈值，返回false if (prioritized &amp;&amp; grade == RuleConstant.FLOW_GRADE_QPS) &#123; long currentTime; long waitInMs; currentTime = TimeUtil.currentTimeMillis(); waitInMs = node.tryOccupyNext(currentTime, acquireCount, count); if (waitInMs &lt; OccupyTimeoutProperty.getOccupyTimeout()) &#123; node.addWaitingRequest(currentTime + waitInMs, acquireCount); node.addOccupiedPass(acquireCount); sleep(waitInMs); // PriorityWaitException indicates that the request will pass after waiting for &#123;@link @waitInMs&#125;. throw new PriorityWaitException(waitInMs); &#125; &#125; return false; &#125; // 小于等于，说明在阈值范围内，返回true return true; &#125; 因此，判断的关键就是int curCount = avgUsedTokens(node); private int avgUsedTokens(Node node) &#123; if (node == null) &#123; return DEFAULT_AVG_USED_TOKENS; &#125; return grade == RuleConstant.FLOW_GRADE_THREAD ? node.curThreadNum() : (int)(node.passQps()); &#125; 因为我们采用的是限流，走node.passQps()逻辑： // 这里又进入了 StatisticNode类 @Override public double passQps() &#123; // 请求量 ÷ 滑动窗口时间间隔 ，得到的就是QPS return rollingCounterInSecond.pass() / rollingCounterInSecond.getWindowIntervalInSec(); &#125; 那么rollingCounterInSecond.pass()是如何得到请求量的呢？ // rollingCounterInSecond 本质是ArrayMetric，之前说过 @Override public long pass() &#123; // 获取当前窗口 data.currentWindow(); long pass = 0; // 获取 当前时间的 滑动窗口范围内 的所有小窗口 List&lt;MetricBucket> list = data.values(); // 遍历 for (MetricBucket window : list) &#123; // 累加求和 pass += window.pass(); &#125; // 返回 return pass; &#125; 来看看data.values()如何获取 滑动窗口范围内 的所有小窗口： // 此处进入LeapArray类中： public List&lt;T> values(long timeMillis) &#123; if (timeMillis &lt; 0) &#123; return new ArrayList&lt;T>(); &#125; // 创建空集合，大小等于 LeapArray长度 int size = array.length(); List&lt;T> result = new ArrayList&lt;T>(size); // 遍历 LeapArray for (int i = 0; i &lt; size; i++) &#123; // 获取每一个小窗口 WindowWrap&lt;T> windowWrap = array.get(i); // 判断这个小窗口是否在 滑动窗口时间范围内（1秒内） if (windowWrap == null || isWindowDeprecated(timeMillis, windowWrap)) &#123; // 不在范围内，则跳过 continue; &#125; // 在范围内，则添加到集合中 result.add(windowWrap.value()); &#125; // 返回集合 return result; &#125; 那么，isWindowDeprecated(timeMillis, windowWrap)又是如何判断窗口是否符合要求呢？ public boolean isWindowDeprecated(long time, WindowWrap&lt;T> windowWrap) &#123; // 当前时间 - 窗口开始时间 是否大于 滑动窗口的最大间隔（1秒） // 也就是说，我们要统计的时 距离当前时间1秒内的 小窗口的 count之和 return time - windowWrap.windowStart() > intervalInMs; &#125; 2.9.3.漏桶上一节我们讲过，FlowSlot的限流判断最终都由TrafficShapingController接口中的canPass方法来实现。该接口有三个实现类： DefaultController：快速失败，默认的方式，基于滑动时间窗口算法 WarmUpController：预热模式，基于滑动时间窗口算法，只不过阈值是动态的 RateLimiterController：排队等待模式，基于漏桶算法 因此，我们跟入默认的RateLimiterController中的canPass方法来分析： @Override public boolean canPass(Node node, int acquireCount, boolean prioritized) &#123; // Pass when acquire count is less or equal than 0. if (acquireCount &lt;= 0) &#123; return true; &#125; // 阈值小于等于 0 ，阻止请求 if (count &lt;= 0) &#123; return false; &#125; // 获取当前时间 long currentTime = TimeUtil.currentTimeMillis(); // 计算两次请求之间允许的最小时间间隔 long costTime = Math.round(1.0 * (acquireCount) / count * 1000); // 计算本次请求 允许执行的时间点 = 最近一次请求的可执行时间 + 两次请求的最小间隔 long expectedTime = costTime + latestPassedTime.get(); // 如果允许执行的时间点小于当前时间，说明可以立即执行 if (expectedTime &lt;= currentTime) &#123; // 更新上一次的请求的执行时间 latestPassedTime.set(currentTime); return true; &#125; else &#123; // 不能立即执行，需要计算 预期等待时长 // 预期等待时长 = 两次请求的最小间隔 +最近一次请求的可执行时间 - 当前时间 long waitTime = costTime + latestPassedTime.get() - TimeUtil.currentTimeMillis(); // 如果预期等待时间超出阈值，则拒绝请求 if (waitTime > maxQueueingTimeMs) &#123; return false; &#125; else &#123; // 预期等待时间小于阈值，更新最近一次请求的可执行时间，加上costTime long oldTime = latestPassedTime.addAndGet(costTime); try &#123; // 保险起见，再判断一次预期等待时间，是否超过阈值 waitTime = oldTime - TimeUtil.currentTimeMillis(); if (waitTime > maxQueueingTimeMs) &#123; // 如果超过，则把刚才 加 的时间再 减回来 latestPassedTime.addAndGet(-costTime); // 拒绝 return false; &#125; // in race condition waitTime may &lt;= 0 if (waitTime > 0) &#123; // 预期等待时间在阈值范围内，休眠要等待的时间，醒来后继续执行 Thread.sleep(waitTime); &#125; return true; &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; return false; &#125; 与我们之前分析的漏桶算法基本一致： 2.10.DegradeSlot最后一关，就是降级规则判断了。 Sentinel的降级是基于状态机来实现的： 对应的实现在DegradeSlot类中，核心API： @Override public void entry(Context context, ResourceWrapper resourceWrapper, DefaultNode node, int count, boolean prioritized, Object... args) throws Throwable &#123; // 熔断降级规则判断 performChecking(context, resourceWrapper); // 继续下一个slot fireEntry(context, resourceWrapper, node, count, prioritized, args); &#125; 继续进入performChecking方法： void performChecking(Context context, ResourceWrapper r) throws BlockException &#123; // 获取当前资源上的所有的断路器 CircuitBreaker List&lt;CircuitBreaker> circuitBreakers = DegradeRuleManager.getCircuitBreakers(r.getName()); if (circuitBreakers == null || circuitBreakers.isEmpty()) &#123; return; &#125; for (CircuitBreaker cb : circuitBreakers) &#123; // 遍历断路器，逐个判断 if (!cb.tryPass(context)) &#123; throw new DegradeException(cb.getRule().getLimitApp(), cb.getRule()); &#125; &#125; &#125; 2.10.1.CircuitBreaker我们进入CircuitBreaker的tryPass方法中： @Override public boolean tryPass(Context context) &#123; // 判断状态机状态 if (currentState.get() == State.CLOSED) &#123; // 如果是closed状态，直接放行 return true; &#125; if (currentState.get() == State.OPEN) &#123; // 如果是OPEN状态，断路器打开 // 继续判断OPEN时间窗是否结束，如果是则把状态从OPEN切换到 HALF_OPEN，返回true return retryTimeoutArrived() &amp;&amp; fromOpenToHalfOpen(context); &#125; // OPEN状态，并且时间窗未到，返回false return false; &#125; 有关时间窗的判断在retryTimeoutArrived()方法： protected boolean retryTimeoutArrived() &#123; // 当前时间 大于 下一次 HalfOpen的重试时间 return TimeUtil.currentTimeMillis() >= nextRetryTimestamp; &#125; OPEN到HALF_OPEN切换在fromOpenToHalfOpen(context)方法： protected boolean fromOpenToHalfOpen(Context context) &#123; // 基于CAS修改状态，从 OPEN到 HALF_OPEN if (currentState.compareAndSet(State.OPEN, State.HALF_OPEN)) &#123; // 状态变更的事件通知 notifyObservers(State.OPEN, State.HALF_OPEN, null); // 得到当前资源 Entry entry = context.getCurEntry(); // 给资源设置监听器，在资源Entry销毁时（资源业务执行完毕时）触发 entry.whenTerminate(new BiConsumer&lt;Context, Entry>() &#123; @Override public void accept(Context context, Entry entry) &#123; // 判断 资源业务是否异常 if (entry.getBlockError() != null) &#123; // 如果异常，则再次进入OPEN状态 currentState.compareAndSet(State.HALF_OPEN, State.OPEN); notifyObservers(State.HALF_OPEN, State.OPEN, 1.0d); &#125; &#125; &#125;); return true; &#125; return false; &#125; 这里出现了从OPEN到HALF_OPEN、从HALF_OPEN到OPEN的变化，但是还有几个没有： 从CLOSED到OPEN 从HALF_OPEN到CLOSED 2.10.2.触发断路器请求经过所有插槽 后，一定会执行exit方法，而在DegradeSlot的exit方法中： 会调用CircuitBreaker的onRequestComplete方法。而CircuitBreaker有两个实现： 我们这里以异常比例熔断为例来看，进入ExceptionCircuitBreaker的onRequestComplete方法： @Override public void onRequestComplete(Context context) &#123; // 获取资源 Entry Entry entry = context.getCurEntry(); if (entry == null) &#123; return; &#125; // 尝试获取 资源中的 异常 Throwable error = entry.getError(); // 获取计数器，同样采用了滑动窗口来计数 SimpleErrorCounter counter = stat.currentWindow().value(); if (error != null) &#123; // 如果出现异常，则 error计数器 +1 counter.getErrorCount().add(1); &#125; // 不管是否出现异常，total计数器 +1 counter.getTotalCount().add(1); // 判断异常比例是否超出阈值 handleStateChangeWhenThresholdExceeded(error); &#125; 来看阈值判断的方法： private void handleStateChangeWhenThresholdExceeded(Throwable error) &#123; // 如果当前已经是OPEN状态，不做处理 if (currentState.get() == State.OPEN) &#123; return; &#125; // 如果已经是 HALF_OPEN 状态，判断是否需求切换状态 if (currentState.get() == State.HALF_OPEN) &#123; if (error == null) &#123; // 没有异常，则从 HALF_OPEN 到 CLOSED fromHalfOpenToClose(); &#125; else &#123; // 有一次，再次进入OPEN fromHalfOpenToOpen(1.0d); &#125; return; &#125; // 说明当前是CLOSE状态，需要判断是否触发阈值 List&lt;SimpleErrorCounter> counters = stat.values(); long errCount = 0; long totalCount = 0; // 累加计算 异常请求数量、总请求数量 for (SimpleErrorCounter counter : counters) &#123; errCount += counter.errorCount.sum(); totalCount += counter.totalCount.sum(); &#125; // 如果总请求数量未达到阈值，什么都不做 if (totalCount &lt; minRequestAmount) &#123; return; &#125; double curCount = errCount; if (strategy == DEGRADE_GRADE_EXCEPTION_RATIO) &#123; // 计算请求的异常比例 curCount = errCount * 1.0d / totalCount; &#125; // 如果比例超过阈值，切换到 OPEN if (curCount > threshold) &#123; transformToOpen(curCount); &#125; &#125;","categories":[{"name":"spring","slug":"spring","permalink":"http://blog.b6123.top/categories/spring/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://blog.b6123.top/tags/springcloud/"}]},{"title":"spiderFlow可视化爬虫工具","slug":"spiderFlow","date":"2022-05-06T02:46:00.000Z","updated":"2022-11-01T02:46:06.331Z","comments":true,"path":"2022/05/06/spiderFlow/","link":"","permalink":"http://blog.b6123.top/2022/05/06/spiderFlow/","excerpt":"","text":"介绍 spider-flow 是一个爬虫平台，以图形化方式定义爬虫流程，无需代码即可实现一个爬虫详情见官方文档可以下载官方代码包相关代码 特性 支持css选择器、正则提取 支持JSON&#x2F;XML格式 支持Xpath&#x2F;JsonPath提取 支持多数据源（mysql&#x2F;redis&#x2F;mongodb）、SQL select&#x2F;insert&#x2F;update&#x2F;delete 支持爬取JS动态渲染的页面 支持代理 支持二进制格式 支持保存&#x2F;读取文件(csv、xls、jpg等) 常用字符串、日期、文件、加解密、随机等函数 支持流程嵌套 支持插件扩展(自定义执行器，自定义函数、自定义Controller、类型扩展等） 支持HTTP接口 插件 redis插件 mongodb插件 IP代理池插件 OSS插件 OCR插件（目前仅支持百度OCR统一文字识别） Selenium插件（集成在maven中） 安装 windows环境的安装很简单，请参考官方文档，下面主要说说linux环境 这里我用的是centos8.2(版本应该影响不大)。其他小伙伴请参考相关的爬虫驱动使用chrome cat &#x2F;etc&#x2F;centos-release #查看当前版本 ####安装chrome curl https:&#x2F;&#x2F;intoli.com&#x2F;install-google-chrome.sh | bash ldd &#x2F;opt&#x2F;google&#x2F;chrome&#x2F;chrome | grep &quot;not found&quot; 安装完成后，执行如下测试命令，会在当前目录下生成一张百度的图片 google-chrome-stable --no-sandbox --headless --disable-gpu --screenshot https://www.baidu.com/ ####安装 chromedriver 查看当前chrome浏览器版本 google-chrome-stable --version 根据指定版本下载chromedriver下载地址官方提供的是zip格式，如果服务器不存在请先安装 unzip # 安装unzip yum install unzip # 解压 unzip chromedriver_linux64.zip 建立软连接或者复制、移动过去(推荐直接复制过去，省事) ln -s 源地址 /usr/bin/chromedriver mv chromedriver /usr/bin/chromedriver 查看chromedriver版本 chromedriver --version ###项目相关配置 application.properties相关配置 selenium 配置 #设置chrome的WebDriver驱动路径，下载地址：http://npm.taobao.org/mirrors/chromedriver/，注意版本问题 selenium.driver.chrome=/usr/bin/chromedriver #设置fireFox的WebDriver驱动路径，下载地址：https://github.com/mozilla/geckodriver/releases #selenium.driver.firefox=E:/driver/geckodriver.exe 定时任务配置 #设置为true时定时任务才生效 spider.job.enable=true 其他数据库地址配置的，相关库需要首先导入项目下的sql文件导入数据库中如果安装了其他插件，如百度ocr，需要另外导入sql，在ocr包下的db目录下 ###项目实战 以下我已爬取80s电影网数据为例子(网站地址) 具体流程图大致为 定义开始节点 定义请求前变量 设置请求配置 定义变量获取页面相关返回值具体的语法请参考官方文档 SpiderResponse 循环设置 定义输出变量，解析每个节点此时 movieList 是一个List,我们要拿到当前循环的Element，获取电影中我们需要的每个属性 输出显示以及入库操作 将根据上一步定义的变量，指定输出。如果需要插入数据库，需要指定数据源。 数据源配置以及数据库设计 测试相关使用 可以看到控制台已经输出日志，检查数据库保存情况可以看到相关数据已经成功传入。 其他坑 如果报错死循环了，可能是因为没有配置 死循环监测（默认5000） #死循环检测(节点执行次数超过该值时认为是死循环)默认值为5000 spider.detect.dead-cycle=1000000","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://blog.b6123.top/categories/%E7%88%AC%E8%99%AB/"},{"name":"可视化工具","slug":"爬虫/可视化工具","permalink":"http://blog.b6123.top/categories/%E7%88%AC%E8%99%AB/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"web爬虫","slug":"web爬虫","permalink":"http://blog.b6123.top/tags/web%E7%88%AC%E8%99%AB/"}]},{"title":"Nacos源码分析","slug":"nacosym","date":"2022-03-22T06:37:36.000Z","updated":"2022-11-01T02:46:06.330Z","comments":true,"path":"2022/03/22/nacosym/","link":"","permalink":"http://blog.b6123.top/2022/03/22/nacosym/","excerpt":"","text":"1.下载Nacos源码并运行要研究Nacos源码自然不能用打包好的Nacos服务端jar包来运行，需要下载源码自己编译来运行。 1.1.下载Nacos源码Nacos的GitHub地址：https://github.com/alibaba/nacos 课前资料中已经提供了下载好的1.4.2版本的Nacos源码： 如果需要研究其他版本的同学，也可以自行下载： 大家找到其release页面：https://github.com/alibaba/nacos/tags，找到其中的1.4.2.版本： 点击进入后，下载Source code(zip)： 1.2.导入Demo工程我们的课前资料提供了一个微服务Demo，包含了服务注册、发现等业务。 导入该项目后，查看其项目结构： 结构说明： cloud-source-demo：项目父目录 cloud-demo：微服务的父工程，管理微服务依赖 order-service：订单微服务，业务中需要访问user-service，是一个服务消费者 user-service：用户微服务，对外暴露根据id查询用户的接口，是一个服务提供者 1.3.导入Nacos源码将之前下载好的Nacos源码解压到cloud-source-demo项目目录中： 然后，使用IDEA将其作为一个module来导入： 1）选择项目结构选项： 然后点击导入module： 在弹出窗口中，选择nacos源码目录： 然后选择maven模块，finish： 最后，点击OK即可： 导入后的项目结构： 1.4.proto编译Nacos底层的数据通信会基于protobuf对数据做序列化和反序列化。并将对应的proto文件定义在了consistency这个子模块中： 我们需要先将proto文件编译为对应的Java代码。 1.4.1.什么是protobufprotobuf的全称是Protocol Buffer，是Google提供的一种数据序列化协议，这是Google官方的定义： Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。 可以简单理解为，是一种跨语言、跨平台的数据传输格式。与json的功能类似，但是无论是性能，还是数据大小都比json要好很多。 protobuf的之所以可以跨语言，就是因为数据定义的格式为.proto格式，需要基于protoc编译为对应的语言。 1.4.2.安装protocProtobuf的GitHub地址：https://github.com/protocolbuffers/protobuf/releases 我们可以下载windows版本的来使用： 另外，课前资料也提供了下载好的安装包： 解压到任意非中文目录下，其中的bin目录中的protoc.exe可以帮助我们编译： 然后将这个bin目录配置到你的环境变量path中，可以参考JDK的配置方式： 1.4.3.编译proto进入nacos-1.4.2的consistency模块下的src&#x2F;main目录下： 然后打开cmd窗口，运行下面的两个命令： protoc --java_out=./java ./proto/consistency.proto protoc --java_out=./java ./proto/Data.proto 如图： 会在nacos的consistency模块中编译出这些java代码： 1.5.运行nacos服务端的入口是在console模块中的Nacos类： 我们需要让它单机启动： 然后新建一个SpringBootApplication： 然后填写应用信息： 然后运行Nacos这个main函数： 将order-service和user-service服务启动后，可以查看nacos控制台： 2.服务注册服务注册到Nacos以后，会保存在一个本地注册表中，其结构如下： 首先最外层是一个Map，结构为：Map&lt;String, Map&lt;String, Service&gt;&gt;： key：是namespace_id，起到环境隔离的作用。namespace下可以有多个group value：又是一个Map&lt;String, Service&gt;，代表分组及组内的服务。一个组内可以有多个服务 key：代表group分组，不过作为key时格式是group_name:service_name value：分组下的某一个服务，例如userservice，用户服务。类型为Service，内部也包含一个Map&lt;String,Cluster&gt;，一个服务下可以有多个集群 key：集群名称 value：Cluster类型，包含集群的具体信息。一个集群中可能包含多个实例，也就是具体的节点信息，其中包含一个Set&lt;Instance&gt;，就是该集群下的实例的集合 Instance：实例信息，包含实例的IP、Port、健康状态、权重等等信息 每一个服务去注册到Nacos时，就会把信息组织并存入这个Map中。 2.1.服务注册接口Nacos提供了服务注册的API接口，客户端只需要向该接口发送请求，即可实现服务注册。 接口说明：注册一个实例到Nacos服务。 请求类型：POST 请求路径：/nacos/v1/ns/instance 请求参数： 名称 类型 是否必选 描述 ip 字符串 是 服务实例IP port int 是 服务实例port namespaceId 字符串 否 命名空间ID weight double 否 权重 enabled boolean 否 是否上线 healthy boolean 否 是否健康 metadata 字符串 否 扩展信息 clusterName 字符串 否 集群名 serviceName 字符串 是 服务名 groupName 字符串 否 分组名 ephemeral boolean 否 是否临时实例 错误编码： 错误代码 描述 语义 400 Bad Request 客户端请求中的语法错误 403 Forbidden 没有权限 404 Not Found 无法找到资源 500 Internal Server Error 服务器内部错误 200 OK 正常 2.2.客户端首先，我们需要找到服务注册的入口。 2.2.1.NacosServiceRegistryAutoConfiguration因为Nacos的客户端是基于SpringBoot的自动装配实现的，我们可以在nacos-discovery依赖： spring-cloud-starter-alibaba-nacos-discovery-2.2.6.RELEASE.jar 这个包中找到Nacos自动装配信息： 可以看到，有很多个自动配置类被加载了，其中跟服务注册有关的就是NacosServiceRegistryAutoConfiguration这个类，我们跟入其中。 可以看到，在NacosServiceRegistryAutoConfiguration这个类中，包含一个跟自动注册有关的Bean： 2.2.2.NacosAutoServiceRegistrationNacosAutoServiceRegistration源码如图： 可以看到在初始化时，其父类AbstractAutoServiceRegistration也被初始化了。 AbstractAutoServiceRegistration如图： 可以看到它实现了ApplicationListener接口，监听Spring容器启动过程中的事件。 在监听到WebServerInitializedEvent（web服务初始化完成）的事件后，执行了bind 方法。 其中的bind方法如下： public void bind(WebServerInitializedEvent event) &#123; // 获取 ApplicationContext ApplicationContext context = event.getApplicationContext(); // 判断服务的 namespace,一般都是null if (context instanceof ConfigurableWebServerApplicationContext) &#123; if (\"management\".equals(((ConfigurableWebServerApplicationContext) context) .getServerNamespace())) &#123; return; &#125; &#125; // 记录当前 web 服务的端口 this.port.compareAndSet(0, event.getWebServer().getPort()); // 启动当前服务注册流程 this.start(); &#125; 其中的start方法流程： public void start() &#123; if (!isEnabled()) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Discovery Lifecycle disabled. Not starting\"); &#125; return; &#125; // 当前服务处于未运行状态时，才进行初始化 if (!this.running.get()) &#123; // 发布服务开始注册的事件 this.context.publishEvent( new InstancePreRegisteredEvent(this, getRegistration())); // ☆☆☆☆开始注册☆☆☆☆ register(); if (shouldRegisterManagement()) &#123; registerManagement(); &#125; // 发布注册完成事件 this.context.publishEvent( new InstanceRegisteredEvent&lt;>(this, getConfiguration())); // 服务状态设置为运行状态，基于AtomicBoolean this.running.compareAndSet(false, true); &#125; &#125; 其中最关键的register()方法就是完成服务注册的关键，代码如下： protected void register() &#123; this.serviceRegistry.register(getRegistration()); &#125; 此处的this.serviceRegistry就是NacosServiceRegistry： 2.2.3.NacosServiceRegistryNacosServiceRegistry是Spring的ServiceRegistry接口的实现类，而ServiceRegistry接口是服务注册、发现的规约接口，定义了register、deregister等方法的声明。 而NacosServiceRegistry对register的实现如下： @Override public void register(Registration registration) &#123; // 判断serviceId是否为空，也就是spring.application.name不能为空 if (StringUtils.isEmpty(registration.getServiceId())) &#123; log.warn(\"No service to register for nacos client...\"); return; &#125; // 获取Nacos的命名服务，其实就是注册中心服务 NamingService namingService = namingService(); // 获取 serviceId 和 Group String serviceId = registration.getServiceId(); String group = nacosDiscoveryProperties.getGroup(); // 封装服务实例的基本信息，如 cluster-name、是否为临时实例、权重、IP、端口等 Instance instance = getNacosInstanceFromRegistration(registration); try &#123; // 开始注册服务 namingService.registerInstance(serviceId, group, instance); log.info(\"nacos registry, &#123;&#125; &#123;&#125; &#123;&#125;:&#123;&#125; register finished\", group, serviceId, instance.getIp(), instance.getPort()); &#125; catch (Exception e) &#123; if (nacosDiscoveryProperties.isFailFast()) &#123; log.error(\"nacos registry, &#123;&#125; register failed...&#123;&#125;,\", serviceId, registration.toString(), e); rethrowRuntimeException(e); &#125; else &#123; log.warn(\"Failfast is false. &#123;&#125; register failed...&#123;&#125;,\", serviceId, registration.toString(), e); &#125; &#125; &#125; 可以看到方法中最终是调用NamingService的registerInstance方法实现注册的。 而NamingService接口的默认实现就是NacosNamingService。 2.2.4.NacosNamingServiceNacosNamingService提供了服务注册、订阅等功能。 其中registerInstance就是注册服务实例，源码如下： @Override public void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException &#123; // 检查超时参数是否异常。心跳超时时间(默认15秒)必须大于心跳周期(默认5秒) NamingUtils.checkInstanceIsLegal(instance); // 拼接得到新的服务名，格式为：groupName@@serviceId String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName); // 判断是否为临时实例，默认为 true。 if (instance.isEphemeral()) &#123; // 如果是临时实例，需要定时向 Nacos 服务发送心跳 BeatInfo beatInfo = beatReactor.buildBeatInfo(groupedServiceName, instance); beatReactor.addBeatInfo(groupedServiceName, beatInfo); &#125; // 发送注册服务实例的请求 serverProxy.registerService(groupedServiceName, groupName, instance); &#125; 最终，由NacosProxy的registerService方法，完成服务注册。 代码如下： public void registerService(String serviceName, String groupName, Instance instance) throws NacosException &#123; NAMING_LOGGER.info(\"[REGISTER-SERVICE] &#123;&#125; registering service &#123;&#125; with instance: &#123;&#125;\", namespaceId, serviceName, instance); // 组织请求参数 final Map&lt;String, String> params = new HashMap&lt;String, String>(16); params.put(CommonParams.NAMESPACE_ID, namespaceId); params.put(CommonParams.SERVICE_NAME, serviceName); params.put(CommonParams.GROUP_NAME, groupName); params.put(CommonParams.CLUSTER_NAME, instance.getClusterName()); params.put(\"ip\", instance.getIp()); params.put(\"port\", String.valueOf(instance.getPort())); params.put(\"weight\", String.valueOf(instance.getWeight())); params.put(\"enable\", String.valueOf(instance.isEnabled())); params.put(\"healthy\", String.valueOf(instance.isHealthy())); params.put(\"ephemeral\", String.valueOf(instance.isEphemeral())); params.put(\"metadata\", JacksonUtils.toJson(instance.getMetadata())); // 通过POST请求将上述参数，发送到 /nacos/v1/ns/instance reqApi(UtilAndComs.nacosUrlInstance, params, HttpMethod.POST); &#125; 这里提交的信息就是Nacos服务注册接口需要的完整参数，核心参数有： namespace_id：环境 service_name：服务名称 group_name：组名称 cluster_name：集群名称 ip: 当前实例的ip地址 port: 当前实例的端口 而在NacosNamingService的registerInstance方法中，有一段是与服务心跳有关的代码，我们在后续会继续学习。 2.2.5.客户端注册的流程图如图： 2.3.服务端在nacos-console的模块中，会引入nacos-naming这个模块： 模块结构如下： 其中的com.alibaba.nacos.naming.controllers包下就有服务注册、发现等相关的各种接口，其中的服务注册是在InstanceController类中： 2.3.1.InstanceController进入InstanceController类，可以看到一个register方法，就是服务注册的方法了： @CanDistro @PostMapping @Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE) public String register(HttpServletRequest request) throws Exception &#123; // 尝试获取namespaceId final String namespaceId = WebUtils .optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); // 尝试获取serviceName，其格式为 group_name@@service_name final String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); // 解析出实例信息，封装为Instance对象 final Instance instance = parseInstance(request); // 注册实例 serviceManager.registerInstance(namespaceId, serviceName, instance); return \"ok\"; &#125; 这里，进入到了serviceManager.registerInstance()方法中。 2.3.2.ServiceManagerServiceManager就是Nacos中管理服务、实例信息的核心API，其中就包含Nacos的服务注册表： 而其中的registerInstance方法就是注册服务实例的方法： /** * Register an instance to a service in AP mode. * * &lt;p>This method creates service or cluster silently if they don't exist. * * @param namespaceId id of namespace * @param serviceName service name * @param instance instance to register * @throws Exception any error occurred in the process */ public void registerInstance(String namespaceId, String serviceName, Instance instance) throws NacosException &#123; // 创建一个空的service（如果是第一次来注册实例，要先创建一个空service出来，放入注册表） // 此时不包含实例信息 createEmptyService(namespaceId, serviceName, instance.isEphemeral()); // 拿到创建好的service Service service = getService(namespaceId, serviceName); // 拿不到则抛异常 if (service == null) &#123; throw new NacosException(NacosException.INVALID_PARAM, \"service not found, namespace: \" + namespaceId + \", service: \" + serviceName); &#125; // 添加要注册的实例到service中 addInstance(namespaceId, serviceName, instance.isEphemeral(), instance); &#125; 创建好了服务，接下来就要添加实例到服务中： /** * Add instance to service. * * @param namespaceId namespace * @param serviceName service name * @param ephemeral whether instance is ephemeral * @param ips instances * @throws NacosException nacos exception */ public void addInstance(String namespaceId, String serviceName, boolean ephemeral, Instance... ips) throws NacosException &#123; // 监听服务列表用到的key，服务唯一标识，例如：com.alibaba.nacos.naming.iplist.ephemeral.public##DEFAULT_GROUP@@order-service String key = KeyBuilder.buildInstanceListKey(namespaceId, serviceName, ephemeral); // 获取服务 Service service = getService(namespaceId, serviceName); // 同步锁，避免并发修改的安全问题 synchronized (service) &#123; // 1）获取要更新的实例列表 List&lt;Instance> instanceList = addIpAddresses(service, ephemeral, ips); // 2）封装实例列表到Instances对象 Instances instances = new Instances(); instances.setInstanceList(instanceList); // 3）完成 注册表更新 以及 Nacos集群的数据同步 consistencyService.put(key, instances); &#125; &#125; 该方法中对修改服务列表的动作加锁处理，确保线程安全。而在同步代码块中，包含下面几步： 1）先获取要更新的实例列表，addIpAddresses(service, ephemeral, ips); 2）然后将更新后的数据封装到Instances对象中，后面更新注册表时使用 3）最后，调用consistencyService.put()方法完成Nacos集群的数据同步，保证集群一致性。 注意：在第1步的addIPAddress中，会拷贝旧的实例列表，添加新实例到列表中。在第3步中，完成对实例状态更新后，则会用新列表直接覆盖旧实例列表。而在更新过程中，旧实例列表不受影响，用户依然可以读取。 这样在更新列表状态过程中，无需阻塞用户的读操作，也不会导致用户读取到脏数据，性能比较好。这种方案称为CopyOnWrite方案。 1）更服务列表我们来看看实例列表的更新，对应的方法是addIpAddresses(service, ephemeral, ips);： private List&lt;Instance> addIpAddresses(Service service, boolean ephemeral, Instance... ips) throws NacosException &#123; return updateIpAddresses(service, UtilsAndCommons.UPDATE_INSTANCE_ACTION_ADD, ephemeral, ips); &#125; 继续进入updateIpAddresses方法： public List&lt;Instance> updateIpAddresses(Service service, String action, boolean ephemeral, Instance... ips) throws NacosException &#123; // 根据namespaceId、serviceName获取当前服务的实例列表，返回值是Datum // 第一次来，肯定是null Datum datum = consistencyService .get(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), ephemeral)); // 得到服务中现有的实例列表 List&lt;Instance> currentIPs = service.allIPs(ephemeral); // 创建map，保存实例列表，key为ip地址，value是Instance对象 Map&lt;String, Instance> currentInstances = new HashMap&lt;>(currentIPs.size()); // 创建Set集合，保存实例的instanceId Set&lt;String> currentInstanceIds = Sets.newHashSet(); // 遍历要现有的实例列表 for (Instance instance : currentIPs) &#123; // 添加到map中 currentInstances.put(instance.toIpAddr(), instance); // 添加instanceId到set中 currentInstanceIds.add(instance.getInstanceId()); &#125; // 创建map，用来保存更新后的实例列表 Map&lt;String, Instance> instanceMap; if (datum != null &amp;&amp; null != datum.value) &#123; // 如果服务中已经有旧的数据，则先保存旧的实例列表 instanceMap = setValid(((Instances) datum.value).getInstanceList(), currentInstances); &#125; else &#123; // 如果没有旧数据，则直接创建新的map instanceMap = new HashMap&lt;>(ips.length); &#125; // 遍历实例列表 for (Instance instance : ips) &#123; // 判断服务中是否包含要注册的实例的cluster信息 if (!service.getClusterMap().containsKey(instance.getClusterName())) &#123; // 如果不包含，创建新的cluster Cluster cluster = new Cluster(instance.getClusterName(), service); cluster.init(); // 将集群放入service的注册表 service.getClusterMap().put(instance.getClusterName(), cluster); Loggers.SRV_LOG .warn(\"cluster: &#123;&#125; not found, ip: &#123;&#125;, will create new cluster with default configuration.\", instance.getClusterName(), instance.toJson()); &#125; // 删除实例 or 新增实例 ？ if (UtilsAndCommons.UPDATE_INSTANCE_ACTION_REMOVE.equals(action)) &#123; instanceMap.remove(instance.getDatumKey()); &#125; else &#123; // 新增实例，instance生成全新的instanceId Instance oldInstance = instanceMap.get(instance.getDatumKey()); if (oldInstance != null) &#123; instance.setInstanceId(oldInstance.getInstanceId()); &#125; else &#123; instance.setInstanceId(instance.generateInstanceId(currentInstanceIds)); &#125; // 放入instance列表 instanceMap.put(instance.getDatumKey(), instance); &#125; &#125; if (instanceMap.size() &lt;= 0 &amp;&amp; UtilsAndCommons.UPDATE_INSTANCE_ACTION_ADD.equals(action)) &#123; throw new IllegalArgumentException( \"ip list can not be empty, service: \" + service.getName() + \", ip list: \" + JacksonUtils .toJson(instanceMap.values())); &#125; // 将instanceMap中的所有实例转为List返回 return new ArrayList&lt;>(instanceMap.values()); &#125; 简单来讲，就是先获取旧的实例列表，然后把新的实例信息与旧的做对比，新的实例就添加，老的实例同步ID。然后返回最新的实例列表。 2）Nacos集群一致性在完成本地服务列表更新后，Nacos又实现了集群一致性更新，调用的是: consistencyService.put(key, instances); 这里的ConsistencyService接口，代表集群一致性的接口，有很多中不同实现： 我们进入DelegateConsistencyServiceImpl来看： @Override public void put(String key, Record value) throws NacosException &#123; // 根据实例是否是临时实例，判断委托对象 mapConsistencyService(key).put(key, value); &#125; 其中的mapConsistencyService(key)方法就是选择委托方式的： private ConsistencyService mapConsistencyService(String key) &#123; // 判断是否是临时实例： // 是，选择 ephemeralConsistencyService，也就是 DistroConsistencyServiceImpl类 // 否，选择 persistentConsistencyService，也就是PersistentConsistencyServiceDelegateImpl return KeyBuilder.matchEphemeralKey(key) ? ephemeralConsistencyService : persistentConsistencyService; &#125; 默认情况下，所有实例都是临时实例，我们关注DistroConsistencyServiceImpl即可。 2.3.4.DistroConsistencyServiceImpl我们来看临时实例的一致性实现：DistroConsistencyServiceImpl类的put方法： public void put(String key, Record value) throws NacosException &#123; // 先将要更新的实例信息写入本地实例列表 onPut(key, value); // 开始集群同步 distroProtocol.sync(new DistroKey(key, KeyBuilder.INSTANCE_LIST_KEY_PREFIX), DataOperation.CHANGE, globalConfig.getTaskDispatchPeriod() / 2); &#125; 这里方法只有两行： onPut(key, value)：其中value就是Instances，要更新的服务信息。这行主要是基于线程池方式，异步的将Service信息写入注册表中(就是那个多重Map) distroProtocol.sync()：就是通过Distro协议将数据同步给集群中的其它Nacos节点 我们先看onPut方法 2.3.4.1.更新本地实例列表1）放入阻塞队列onPut方法如下： public void onPut(String key, Record value) &#123; // 判断是否是临时实例 if (KeyBuilder.matchEphemeralInstanceListKey(key)) &#123; // 封装 Instances 信息到 数据集：Datum Datum&lt;Instances> datum = new Datum&lt;>(); datum.value = (Instances) value; datum.key = key; datum.timestamp.incrementAndGet(); // 放入DataStore dataStore.put(key, datum); &#125; if (!listeners.containsKey(key)) &#123; return; &#125; // 放入阻塞队列，这里的 notifier维护了一个阻塞队列，并且基于线程池异步执行队列中的任务 notifier.addTask(key, DataOperation.CHANGE); &#125; notifier的类型就是DistroConsistencyServiceImpl.Notifier，内部维护了一个阻塞队列，存放服务列表变更的事件： addTask时，将任务加入该阻塞队列： // DistroConsistencyServiceImpl.Notifier类的 addTask 方法： public void addTask(String datumKey, DataOperation action) &#123; if (services.containsKey(datumKey) &amp;&amp; action == DataOperation.CHANGE) &#123; return; &#125; if (action == DataOperation.CHANGE) &#123; services.put(datumKey, StringUtils.EMPTY); &#125; // 任务放入阻塞队列 tasks.offer(Pair.with(datumKey, action)); &#125; 2）Notifier异步更新同时，notifier还是一个Runnable，通过一个单线程的线程池来不断从阻塞队列中获取任务，执行服务列表的更新。来看下其中的run方法： // DistroConsistencyServiceImpl.Notifier类的run方法： @Override public void run() &#123; Loggers.DISTRO.info(\"distro notifier started\"); // 死循环，不断执行任务。因为是阻塞队列，不会导致CPU负载过高 for (; ; ) &#123; try &#123; // 从阻塞队列中获取任务 Pair&lt;String, DataOperation> pair = tasks.take(); // 处理任务，更新服务列表 handle(pair); &#125; catch (Throwable e) &#123; Loggers.DISTRO.error(\"[NACOS-DISTRO] Error while handling notifying task\", e); &#125; &#125; &#125; 来看看handle方法： // DistroConsistencyServiceImpl.Notifier类的 handle 方法： private void handle(Pair&lt;String, DataOperation> pair) &#123; try &#123; String datumKey = pair.getValue0(); DataOperation action = pair.getValue1(); services.remove(datumKey); int count = 0; if (!listeners.containsKey(datumKey)) &#123; return; &#125; // 遍历，找到变化的service，这里的 RecordListener就是 Service for (RecordListener listener : listeners.get(datumKey)) &#123; count++; try &#123; // 服务的实例列表CHANGE事件 if (action == DataOperation.CHANGE) &#123; // 更新服务列表 listener.onChange(datumKey, dataStore.get(datumKey).value); continue; &#125; // 服务的实例列表 DELETE 事件 if (action == DataOperation.DELETE) &#123; listener.onDelete(datumKey); continue; &#125; &#125; catch (Throwable e) &#123; Loggers.DISTRO.error(\"[NACOS-DISTRO] error while notifying listener of key: &#123;&#125;\", datumKey, e); &#125; &#125; if (Loggers.DISTRO.isDebugEnabled()) &#123; Loggers.DISTRO .debug(\"[NACOS-DISTRO] datum change notified, key: &#123;&#125;, listener count: &#123;&#125;, action: &#123;&#125;\", datumKey, count, action.name()); &#125; &#125; catch (Throwable e) &#123; Loggers.DISTRO.error(\"[NACOS-DISTRO] Error while handling notifying task\", e); &#125; &#125; 3）覆盖实例列表而在Service的onChange方法中，就可以看到更新实例列表的逻辑了： @Override public void onChange(String key, Instances value) throws Exception &#123; Loggers.SRV_LOG.info(\"[NACOS-RAFT] datum is changed, key: &#123;&#125;, value: &#123;&#125;\", key, value); // 更新实例列表 updateIPs(value.getInstanceList(), KeyBuilder.matchEphemeralInstanceListKey(key)); recalculateChecksum(); &#125; updateIPs方法： public void updateIPs(Collection&lt;Instance> instances, boolean ephemeral) &#123; // 准备一个Map，key是cluster，值是集群下的Instance集合 Map&lt;String, List&lt;Instance>> ipMap = new HashMap&lt;>(clusterMap.size()); // 获取服务的所有cluster名称 for (String clusterName : clusterMap.keySet()) &#123; ipMap.put(clusterName, new ArrayList&lt;>()); &#125; // 遍历要更新的实例 for (Instance instance : instances) &#123; try &#123; if (instance == null) &#123; Loggers.SRV_LOG.error(\"[NACOS-DOM] received malformed ip: null\"); continue; &#125; // 判断实例是否包含clusterName，没有的话用默认cluster if (StringUtils.isEmpty(instance.getClusterName())) &#123; instance.setClusterName(UtilsAndCommons.DEFAULT_CLUSTER_NAME); &#125; // 判断cluster是否存在，不存在则创建新的cluster if (!clusterMap.containsKey(instance.getClusterName())) &#123; Loggers.SRV_LOG .warn(\"cluster: &#123;&#125; not found, ip: &#123;&#125;, will create new cluster with default configuration.\", instance.getClusterName(), instance.toJson()); Cluster cluster = new Cluster(instance.getClusterName(), this); cluster.init(); getClusterMap().put(instance.getClusterName(), cluster); &#125; // 获取当前cluster实例的集合，不存在则创建新的 List&lt;Instance> clusterIPs = ipMap.get(instance.getClusterName()); if (clusterIPs == null) &#123; clusterIPs = new LinkedList&lt;>(); ipMap.put(instance.getClusterName(), clusterIPs); &#125; // 添加新的实例到 Instance 集合 clusterIPs.add(instance); &#125; catch (Exception e) &#123; Loggers.SRV_LOG.error(\"[NACOS-DOM] failed to process ip: \" + instance, e); &#125; &#125; for (Map.Entry&lt;String, List&lt;Instance>> entry : ipMap.entrySet()) &#123; //make every ip mine List&lt;Instance> entryIPs = entry.getValue(); // 将实例集合更新到 clusterMap（注册表） clusterMap.get(entry.getKey()).updateIps(entryIPs, ephemeral); &#125; setLastModifiedMillis(System.currentTimeMillis()); // 发布服务变更的通知消息 getPushService().serviceChanged(this); StringBuilder stringBuilder = new StringBuilder(); for (Instance instance : allIPs()) &#123; stringBuilder.append(instance.toIpAddr()).append(\"_\").append(instance.isHealthy()).append(\",\"); &#125; Loggers.EVT_LOG.info(\"[IP-UPDATED] namespace: &#123;&#125;, service: &#123;&#125;, ips: &#123;&#125;\", getNamespaceId(), getName(), stringBuilder.toString()); &#125; 在第45行的代码中：clusterMap.get(entry.getKey()).updateIps(entryIPs, ephemeral); 就是在更新注册表： public void updateIps(List&lt;Instance> ips, boolean ephemeral) &#123; // 获取旧实例列表 Set&lt;Instance> toUpdateInstances = ephemeral ? ephemeralInstances : persistentInstances; HashMap&lt;String, Instance> oldIpMap = new HashMap&lt;>(toUpdateInstances.size()); for (Instance ip : toUpdateInstances) &#123; oldIpMap.put(ip.getDatumKey(), ip); &#125; // 检查新加入实例的状态 List&lt;Instance> newIPs = subtract(ips, oldIpMap.values()); if (newIPs.size() > 0) &#123; Loggers.EVT_LOG .info(\"&#123;&#125; &#123;SYNC&#125; &#123;IP-NEW&#125; cluster: &#123;&#125;, new ips size: &#123;&#125;, content: &#123;&#125;\", getService().getName(), getName(), newIPs.size(), newIPs.toString()); for (Instance ip : newIPs) &#123; HealthCheckStatus.reset(ip); &#125; &#125; // 移除要删除的实例 List&lt;Instance> deadIPs = subtract(oldIpMap.values(), ips); if (deadIPs.size() > 0) &#123; Loggers.EVT_LOG .info(\"&#123;&#125; &#123;SYNC&#125; &#123;IP-DEAD&#125; cluster: &#123;&#125;, dead ips size: &#123;&#125;, content: &#123;&#125;\", getService().getName(), getName(), deadIPs.size(), deadIPs.toString()); for (Instance ip : deadIPs) &#123; HealthCheckStatus.remv(ip); &#125; &#125; toUpdateInstances = new HashSet&lt;>(ips); // 直接覆盖旧实例列表 if (ephemeral) &#123; ephemeralInstances = toUpdateInstances; &#125; else &#123; persistentInstances = toUpdateInstances; &#125; &#125; 2.3.4.2.集群数据同步在DistroConsistencyServiceImpl的put方法中分为两步： 其中的onPut方法已经分析过了。 下面的distroProtocol.sync()就是集群同步的逻辑了。 DistroProtocol类的sync方法如下： public void sync(DistroKey distroKey, DataOperation action, long delay) &#123; // 遍历 Nacos 集群中除自己以外的其它节点 for (Member each : memberManager.allMembersWithoutSelf()) &#123; DistroKey distroKeyWithTarget = new DistroKey(distroKey.getResourceKey(), distroKey.getResourceType(), each.getAddress()); // 定义一个Distro的同步任务 DistroDelayTask distroDelayTask = new DistroDelayTask(distroKeyWithTarget, action, delay); // 交给线程池去执行 distroTaskEngineHolder.getDelayTaskExecuteEngine().addTask(distroKeyWithTarget, distroDelayTask); if (Loggers.DISTRO.isDebugEnabled()) &#123; Loggers.DISTRO.debug(\"[DISTRO-SCHEDULE] &#123;&#125; to &#123;&#125;\", distroKey, each.getAddress()); &#125; &#125; &#125; 其中同步的任务封装为一个DistroDelayTask对象。 交给了distroTaskEngineHolder.getDelayTaskExecuteEngine()执行，这行代码的返回值是： NacosDelayTaskExecuteEngine，这个类维护了一个线程池，并且接收任务，执行任务。 执行任务的方法为processTasks()方法： protected void processTasks() &#123; Collection&lt;Object> keys = getAllTaskKeys(); for (Object taskKey : keys) &#123; AbstractDelayTask task = removeTask(taskKey); if (null == task) &#123; continue; &#125; NacosTaskProcessor processor = getProcessor(taskKey); if (null == processor) &#123; getEngineLog().error(\"processor not found for task, so discarded. \" + task); continue; &#125; try &#123; // 尝试执行同步任务，如果失败会重试 if (!processor.process(task)) &#123; retryFailedTask(taskKey, task); &#125; &#125; catch (Throwable e) &#123; getEngineLog().error(\"Nacos task execute error : \" + e.toString(), e); retryFailedTask(taskKey, task); &#125; &#125; &#125; 可以看出来基于Distro模式的同步是异步进行的，并且失败时会将任务重新入队并充实，因此不保证同步结果的强一致性，属于AP模式的一致性策略。 2.3.5.服务端流程图 2.4.总结 Nacos的注册表结构是什么样的？ 答：Nacos是多级存储模型，最外层通过namespace来实现环境隔离，然后是group分组，分组下就是服务，一个服务有可以分为不同的集群，集群中包含多个实例。因此其注册表结构为一个Map，类型是： Map&lt;String, Map&lt;String, Service&gt;&gt;， 外层key是namespace_id，内层key是group+serviceName. Service内部维护一个Map，结构是：Map&lt;String,Cluster&gt;，key是clusterName，值是集群信息 Cluster内部维护一个Set集合，元素是Instance类型，代表集群中的多个实例。 Nacos如何保证并发写的安全性？ 答：首先，在注册实例时，会对service加锁，不同service之间本身就不存在并发写问题，互不影响。相同service时通过锁来互斥。并且，在更新实例列表时，是基于异步的线程池来完成，而线程池的线程数量为1. Nacos如何避免并发读写的冲突？ 答：Nacos在更新实例列表时，会采用CopyOnWrite技术，首先将Old实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。 Nacos如何应对阿里内部数十万服务的并发写请求？ 答：Nacos内部会将服务注册的任务放入阻塞队列，采用线程池异步来完成实例更新，从而提高并发写能力。 3.服务心跳Nacos的实例分为临时实例和永久实例两种，可以通过在yaml 文件配置： spring: application: name: order-service cloud: nacos: discovery: ephemeral: false # 设置实例为永久实例。true：临时; false：永久 server-addr: 192.168.150.1:8845 临时实例基于心跳方式做健康检测，而永久实例则是由Nacos主动探测实例状态。 其中Nacos提供的心跳的API接口为： 接口描述：发送某个实例的心跳 请求类型：PUT 请求路径： /nacos/v1/ns/instance/beat 请求参数： 名称 类型 是否必选 描述 serviceName 字符串 是 服务名 groupName 字符串 否 分组名 ephemeral boolean 否 是否临时实例 beat JSON格式字符串 是 实例心跳内容 错误编码： 错误代码 描述 语义 400 Bad Request 客户端请求中的语法错误 403 Forbidden 没有权限 404 Not Found 无法找到资源 500 Internal Server Error 服务器内部错误 200 OK 正常 3.1.客户端在2.2.4.服务注册这一节中，我们说过NacosNamingService这个类实现了服务的注册，同时也实现了服务心跳： @Override public void registerInstance(String serviceName, String groupName, Instance instance) throws NacosException &#123; NamingUtils.checkInstanceIsLegal(instance); String groupedServiceName = NamingUtils.getGroupedName(serviceName, groupName); // 判断是否是临时实例。 if (instance.isEphemeral()) &#123; // 如果是临时实例，则构建心跳信息BeatInfo BeatInfo beatInfo = beatReactor.buildBeatInfo(groupedServiceName, instance); // 添加心跳任务 beatReactor.addBeatInfo(groupedServiceName, beatInfo); &#125; serverProxy.registerService(groupedServiceName, groupName, instance); &#125; 3.1.1.BeatInfo这里的BeanInfo就包含心跳需要的各种信息： 3.1.2.BeatReactor而BeatReactor这个类则维护了一个线程池： 当调用BeatReactor的.addBeatInfo(groupedServiceName, beatInfo)方法时，就会执行心跳： public void addBeatInfo(String serviceName, BeatInfo beatInfo) &#123; NAMING_LOGGER.info(\"[BEAT] adding beat: &#123;&#125; to beat map.\", beatInfo); String key = buildKey(serviceName, beatInfo.getIp(), beatInfo.getPort()); BeatInfo existBeat = null; //fix #1733 if ((existBeat = dom2Beat.remove(key)) != null) &#123; existBeat.setStopped(true); &#125; dom2Beat.put(key, beatInfo); // 利用线程池，定期执行心跳任务，周期为 beatInfo.getPeriod() executorService.schedule(new BeatTask(beatInfo), beatInfo.getPeriod(), TimeUnit.MILLISECONDS); MetricsMonitor.getDom2BeatSizeMonitor().set(dom2Beat.size()); &#125; 心跳周期的默认值在com.alibaba.nacos.api.common.Constants类中： 可以看到是5秒，默认5秒一次心跳。 3.1.3.BeatTask心跳的任务封装在BeatTask这个类中，是一个Runnable，其run方法如下： @Override public void run() &#123; if (beatInfo.isStopped()) &#123; return; &#125; // 获取心跳周期 long nextTime = beatInfo.getPeriod(); try &#123; // 发送心跳 JsonNode result = serverProxy.sendBeat(beatInfo, BeatReactor.this.lightBeatEnabled); long interval = result.get(\"clientBeatInterval\").asLong(); boolean lightBeatEnabled = false; if (result.has(CommonParams.LIGHT_BEAT_ENABLED)) &#123; lightBeatEnabled = result.get(CommonParams.LIGHT_BEAT_ENABLED).asBoolean(); &#125; BeatReactor.this.lightBeatEnabled = lightBeatEnabled; if (interval > 0) &#123; nextTime = interval; &#125; // 判断心跳结果 int code = NamingResponseCode.OK; if (result.has(CommonParams.CODE)) &#123; code = result.get(CommonParams.CODE).asInt(); &#125; if (code == NamingResponseCode.RESOURCE_NOT_FOUND) &#123; // 如果失败，则需要 重新注册实例 Instance instance = new Instance(); instance.setPort(beatInfo.getPort()); instance.setIp(beatInfo.getIp()); instance.setWeight(beatInfo.getWeight()); instance.setMetadata(beatInfo.getMetadata()); instance.setClusterName(beatInfo.getCluster()); instance.setServiceName(beatInfo.getServiceName()); instance.setInstanceId(instance.getInstanceId()); instance.setEphemeral(true); try &#123; serverProxy.registerService(beatInfo.getServiceName(), NamingUtils.getGroupName(beatInfo.getServiceName()), instance); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125; catch (NacosException ex) &#123; NAMING_LOGGER.error(\"[CLIENT-BEAT] failed to send beat: &#123;&#125;, code: &#123;&#125;, msg: &#123;&#125;\", JacksonUtils.toJson(beatInfo), ex.getErrCode(), ex.getErrMsg()); &#125; catch (Exception unknownEx) &#123; NAMING_LOGGER.error(\"[CLIENT-BEAT] failed to send beat: &#123;&#125;, unknown exception msg: &#123;&#125;\", JacksonUtils.toJson(beatInfo), unknownEx.getMessage(), unknownEx); &#125; finally &#123; executorService.schedule(new BeatTask(beatInfo), nextTime, TimeUnit.MILLISECONDS); &#125; &#125; 3.1.5.发送心跳最终心跳的发送还是通过NamingProxy的sendBeat方法来实现： public JsonNode sendBeat(BeatInfo beatInfo, boolean lightBeatEnabled) throws NacosException &#123; if (NAMING_LOGGER.isDebugEnabled()) &#123; NAMING_LOGGER.debug(\"[BEAT] &#123;&#125; sending beat to server: &#123;&#125;\", namespaceId, beatInfo.toString()); &#125; // 组织请求参数 Map&lt;String, String> params = new HashMap&lt;String, String>(8); Map&lt;String, String> bodyMap = new HashMap&lt;String, String>(2); if (!lightBeatEnabled) &#123; bodyMap.put(\"beat\", JacksonUtils.toJson(beatInfo)); &#125; params.put(CommonParams.NAMESPACE_ID, namespaceId); params.put(CommonParams.SERVICE_NAME, beatInfo.getServiceName()); params.put(CommonParams.CLUSTER_NAME, beatInfo.getCluster()); params.put(\"ip\", beatInfo.getIp()); params.put(\"port\", String.valueOf(beatInfo.getPort())); // 发送请求，这个地址就是：/v1/ns/instance/beat String result = reqApi(UtilAndComs.nacosUrlBase + \"/instance/beat\", params, bodyMap, HttpMethod.PUT); return JacksonUtils.toObj(result); &#125; 3.2.服务端对于临时实例，服务端代码分两部分： 1）InstanceController提供了一个接口，处理客户端的心跳请求 2）定时检测实例心跳是否按期执行 3.2.1.InstanceController与服务注册时一样，在nacos-naming模块中的InstanceController类中，定义了一个方法用来处理心跳请求： @CanDistro @PutMapping(\"/beat\") @Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE) public ObjectNode beat(HttpServletRequest request) throws Exception &#123; // 解析心跳的请求参数 ObjectNode result = JacksonUtils.createEmptyJsonNode(); result.put(SwitchEntry.CLIENT_BEAT_INTERVAL, switchDomain.getClientBeatInterval()); String beat = WebUtils.optional(request, \"beat\", StringUtils.EMPTY); RsInfo clientBeat = null; if (StringUtils.isNotBlank(beat)) &#123; clientBeat = JacksonUtils.toObj(beat, RsInfo.class); &#125; String clusterName = WebUtils .optional(request, CommonParams.CLUSTER_NAME, UtilsAndCommons.DEFAULT_CLUSTER_NAME); String ip = WebUtils.optional(request, \"ip\", StringUtils.EMPTY); int port = Integer.parseInt(WebUtils.optional(request, \"port\", \"0\")); if (clientBeat != null) &#123; if (StringUtils.isNotBlank(clientBeat.getCluster())) &#123; clusterName = clientBeat.getCluster(); &#125; else &#123; // fix #2533 clientBeat.setCluster(clusterName); &#125; ip = clientBeat.getIp(); port = clientBeat.getPort(); &#125; String namespaceId = WebUtils.optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); Loggers.SRV_LOG.debug(\"[CLIENT-BEAT] full arguments: beat: &#123;&#125;, serviceName: &#123;&#125;\", clientBeat, serviceName); // 尝试根据参数中的namespaceId、serviceName、clusterName、ip、port等信息 // 从Nacos的注册表中 获取实例 Instance instance = serviceManager.getInstance(namespaceId, serviceName, clusterName, ip, port); // 如果获取失败，说明心跳失败，实例尚未注册 if (instance == null) &#123; if (clientBeat == null) &#123; result.put(CommonParams.CODE, NamingResponseCode.RESOURCE_NOT_FOUND); return result; &#125; Loggers.SRV_LOG.warn(\"[CLIENT-BEAT] The instance has been removed for health mechanism, \" + \"perform data compensation operations, beat: &#123;&#125;, serviceName: &#123;&#125;\", clientBeat, serviceName); // 这里重新注册一个实例 instance = new Instance(); instance.setPort(clientBeat.getPort()); instance.setIp(clientBeat.getIp()); instance.setWeight(clientBeat.getWeight()); instance.setMetadata(clientBeat.getMetadata()); instance.setClusterName(clusterName); instance.setServiceName(serviceName); instance.setInstanceId(instance.getInstanceId()); instance.setEphemeral(clientBeat.isEphemeral()); serviceManager.registerInstance(namespaceId, serviceName, instance); &#125; // 尝试基于namespaceId和serviceName从 注册表中获取Service服务 Service service = serviceManager.getService(namespaceId, serviceName); // 如果不存在，说明服务不存在，返回404 if (service == null) &#123; throw new NacosException(NacosException.SERVER_ERROR, \"service not found: \" + serviceName + \"@\" + namespaceId); &#125; if (clientBeat == null) &#123; clientBeat = new RsInfo(); clientBeat.setIp(ip); clientBeat.setPort(port); clientBeat.setCluster(clusterName); &#125; // 如果心跳没问题，开始处理心跳结果 service.processClientBeat(clientBeat); result.put(CommonParams.CODE, NamingResponseCode.OK); if (instance.containsMetadata(PreservedMetadataKeys.HEART_BEAT_INTERVAL)) &#123; result.put(SwitchEntry.CLIENT_BEAT_INTERVAL, instance.getInstanceHeartBeatInterval()); &#125; result.put(SwitchEntry.LIGHT_BEAT_ENABLED, switchDomain.isLightBeatEnabled()); return result; &#125; 最终，在确认心跳请求对应的服务、实例都在的情况下，开始交给Service类处理这次心跳请求。调用了Service的processClientBeat方法 3.2.2.处理心跳请求查看Service的service.processClientBeat(clientBeat);方法： public void processClientBeat(final RsInfo rsInfo) &#123; ClientBeatProcessor clientBeatProcessor = new ClientBeatProcessor(); clientBeatProcessor.setService(this); clientBeatProcessor.setRsInfo(rsInfo); HealthCheckReactor.scheduleNow(clientBeatProcessor); &#125; 可以看到心跳信息被封装到了 ClientBeatProcessor类中，交给了HealthCheckReactor处理，HealthCheckReactor就是对线程池的封装，不用过多查看。 关键的业务逻辑都在ClientBeatProcessor这个类中，它是一个Runnable，其中的run方法如下： @Override public void run() &#123; Service service = this.service; if (Loggers.EVT_LOG.isDebugEnabled()) &#123; Loggers.EVT_LOG.debug(\"[CLIENT-BEAT] processing beat: &#123;&#125;\", rsInfo.toString()); &#125; String ip = rsInfo.getIp(); String clusterName = rsInfo.getCluster(); int port = rsInfo.getPort(); // 获取集群信息 Cluster cluster = service.getClusterMap().get(clusterName); // 获取集群中的所有实例信息 List&lt;Instance> instances = cluster.allIPs(true); for (Instance instance : instances) &#123; // 找到心跳的这个实例 if (instance.getIp().equals(ip) &amp;&amp; instance.getPort() == port) &#123; if (Loggers.EVT_LOG.isDebugEnabled()) &#123; Loggers.EVT_LOG.debug(\"[CLIENT-BEAT] refresh beat: &#123;&#125;\", rsInfo.toString()); &#125; // 更新实例的最后一次心跳时间 lastBeat instance.setLastBeat(System.currentTimeMillis()); if (!instance.isMarked()) &#123; if (!instance.isHealthy()) &#123; instance.setHealthy(true); Loggers.EVT_LOG .info(\"service: &#123;&#125; &#123;POS&#125; &#123;IP-ENABLED&#125; valid: &#123;&#125;:&#123;&#125;@&#123;&#125;, region: &#123;&#125;, msg: client beat ok\", cluster.getService().getName(), ip, port, cluster.getName(), UtilsAndCommons.LOCALHOST_SITE); getPushService().serviceChanged(service); &#125; &#125; &#125; &#125; &#125; 处理心跳请求的核心就是更新心跳实例的最后一次心跳时间，lastBeat，这个会成为判断实例心跳是否过期的关键指标！ 3.3.3.心跳异常检测在服务注册时，一定会创建一个Service对象，而Service中有一个init方法，会在注册时被调用： public void init() &#123; // 开启心跳检测的任务 HealthCheckReactor.scheduleCheck(clientBeatCheckTask); for (Map.Entry&lt;String, Cluster> entry : clusterMap.entrySet()) &#123; entry.getValue().setService(this); entry.getValue().init(); &#125; &#125; 其中HealthCheckReactor.scheduleCheck就是执行心跳检测的定时任务： 可以看到，该任务是5000ms执行一次，也就是5秒对实例的心跳状态做一次检测。 此处的ClientBeatCheckTask同样是一个Runnable，其中的run方法为： @Override public void run() &#123; try &#123; // 找到所有临时实例的列表 List&lt;Instance> instances = service.allIPs(true); // first set health status of instances: for (Instance instance : instances) &#123; // 判断 心跳间隔（当前时间 - 最后一次心跳时间） 是否大于 心跳超时时间，默认15秒 if (System.currentTimeMillis() - instance.getLastBeat() > instance.getInstanceHeartBeatTimeOut()) &#123; if (!instance.isMarked()) &#123; if (instance.isHealthy()) &#123; // 如果超时，标记实例为不健康 healthy = false instance.setHealthy(false); // 发布实例状态变更的事件 getPushService().serviceChanged(service); ApplicationUtils.publishEvent(new InstanceHeartbeatTimeoutEvent(this, instance)); &#125; &#125; &#125; &#125; if (!getGlobalConfig().isExpireInstance()) &#123; return; &#125; // then remove obsolete instances: for (Instance instance : instances) &#123; if (instance.isMarked()) &#123; continue; &#125; // 判断心跳间隔（当前时间 - 最后一次心跳时间）是否大于 实例被删除的最长超时时间，默认30秒 if (System.currentTimeMillis() - instance.getLastBeat() > instance.getIpDeleteTimeout()) &#123; // 如果是超过了30秒，则删除实例 Loggers.SRV_LOG.info(\"[AUTO-DELETE-IP] service: &#123;&#125;, ip: &#123;&#125;\", service.getName(), JacksonUtils.toJson(instance)); deleteIp(instance); &#125; &#125; &#125; catch (Exception e) &#123; Loggers.SRV_LOG.warn(\"Exception while processing client beat time out.\", e); &#125; &#125; 其中的超时时间同样是在com.alibaba.nacos.api.common.Constants这个类中： 3.3.4.主动健康检测对于非临时实例（ephemeral&#x3D;false)，Nacos会采用主动的健康检测，定时向实例发送请求，根据响应来判断实例健康状态。 入口在2.3.2小节的ServiceManager类中的registerInstance方法： 创建空服务时： public void createEmptyService(String namespaceId, String serviceName, boolean local) throws NacosException &#123; // 如果服务不存在，创建新的服务 createServiceIfAbsent(namespaceId, serviceName, local, null); &#125; 创建服务流程： public void createServiceIfAbsent(String namespaceId, String serviceName, boolean local, Cluster cluster) throws NacosException &#123; // 尝试获取服务 Service service = getService(namespaceId, serviceName); if (service == null) &#123; // 发现服务不存在，开始创建新服务 Loggers.SRV_LOG.info(\"creating empty service &#123;&#125;:&#123;&#125;\", namespaceId, serviceName); service = new Service(); service.setName(serviceName); service.setNamespaceId(namespaceId); service.setGroupName(NamingUtils.getGroupName(serviceName)); // now validate the service. if failed, exception will be thrown service.setLastModifiedMillis(System.currentTimeMillis()); service.recalculateChecksum(); if (cluster != null) &#123; cluster.setService(service); service.getClusterMap().put(cluster.getName(), cluster); &#125; service.validate(); // ** 写入注册表并初始化 ** putServiceAndInit(service); if (!local) &#123; addOrReplaceService(service); &#125; &#125; &#125; 关键在putServiceAndInit(service)方法中： private void putServiceAndInit(Service service) throws NacosException &#123; // 将服务写入注册表 putService(service); service = getService(service.getNamespaceId(), service.getName()); // 完成服务的初始化 service.init(); consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), true), service); consistencyService .listen(KeyBuilder.buildInstanceListKey(service.getNamespaceId(), service.getName(), false), service); Loggers.SRV_LOG.info(\"[NEW-SERVICE] &#123;&#125;\", service.toJson()); &#125; 进入初始化逻辑：service.init()，这个会进入Service类中： /** * Init service. */ public void init() &#123; // 开启临时实例的心跳监测任务 HealthCheckReactor.scheduleCheck(clientBeatCheckTask); // 遍历注册表中的集群 for (Map.Entry&lt;String, Cluster> entry : clusterMap.entrySet()) &#123; entry.getValue().setService(this); // 完成集群初识化 entry.getValue().init(); &#125; &#125; 这里集群的初始化 entry.getValue().init();会进入Cluster类型的init()方法： /** * Init cluster. */ public void init() &#123; if (inited) &#123; return; &#125; // 创建健康检测的任务 checkTask = new HealthCheckTask(this); // 这里会开启对 非临时实例的 定时健康检测 HealthCheckReactor.scheduleCheck(checkTask); inited = true; &#125; 这里的HealthCheckReactor.scheduleCheck(checkTask);会开启定时任务，对非临时实例做健康检测。检测逻辑定义在HealthCheckTask这个类中，是一个Runnable，其中的run方法： public void run() &#123; try &#123; if (distroMapper.responsible(cluster.getService().getName()) &amp;&amp; switchDomain .isHealthCheckEnabled(cluster.getService().getName())) &#123; // 开始健康检测 healthCheckProcessor.process(this); // 记录日志 。。。 &#125; &#125; catch (Throwable e) &#123; // 记录日志 。。。 &#125; finally &#123; if (!cancelled) &#123; // 结束后，再次进行任务调度，一定延迟后执行 HealthCheckReactor.scheduleCheck(this); // 。。。 &#125; &#125; &#125; 健康检测逻辑定义在healthCheckProcessor.process(this);方法中，在HealthCheckProcessor接口中，这个接口也有很多实现，默认是TcpSuperSenseProcessor： 进入TcpSuperSenseProcessor的process方法： @Override public void process(HealthCheckTask task) &#123; // 获取所有 非临时实例的 集合 List&lt;Instance> ips = task.getCluster().allIPs(false); if (CollectionUtils.isEmpty(ips)) &#123; return; &#125; for (Instance ip : ips) &#123; // 封装健康检测信息到 Beat Beat beat = new Beat(ip, task); // 放入一个阻塞队列中 taskQueue.add(beat); MetricsMonitor.getTcpHealthCheckMonitor().incrementAndGet(); &#125; &#125; 可以看到，所有的健康检测任务都被放入一个阻塞队列，而不是立即执行了。这里又采用了异步执行的策略，可以看到Nacos中大量这样的设计。 而TcpSuperSenseProcessor本身就是一个Runnable，在它的构造函数中会把自己放入线程池中去执行，其run方法如下： public void run() &#123; while (true) &#123; try &#123; // 处理任务 processTask(); // ... &#125; catch (Throwable e) &#123; SRV_LOG.error(\"[HEALTH-CHECK] error while processing NIO task\", e); &#125; &#125; &#125; 通过processTask来处理健康检测的任务： private void processTask() throws Exception &#123; // 将任务封装为一个 TaskProcessor，并放入集合 Collection&lt;Callable&lt;Void>> tasks = new LinkedList&lt;>(); do &#123; Beat beat = taskQueue.poll(CONNECT_TIMEOUT_MS / 2, TimeUnit.MILLISECONDS); if (beat == null) &#123; return; &#125; tasks.add(new TaskProcessor(beat)); &#125; while (taskQueue.size() > 0 &amp;&amp; tasks.size() &lt; NIO_THREAD_COUNT * 64); // 批量处理集合中的任务 for (Future&lt;?> f : GlobalExecutor.invokeAllTcpSuperSenseTask(tasks)) &#123; f.get(); &#125; &#125; 任务被封装到了TaskProcessor中去执行了，TaskProcessor是一个Callable，其中的call方法： @Override public Void call() &#123; // 获取检测任务已经等待的时长 long waited = System.currentTimeMillis() - beat.getStartTime(); if (waited > MAX_WAIT_TIME_MILLISECONDS) &#123; Loggers.SRV_LOG.warn(\"beat task waited too long: \" + waited + \"ms\"); &#125; SocketChannel channel = null; try &#123; // 获取实例信息 Instance instance = beat.getIp(); // 通过NIO建立TCP连接 channel = SocketChannel.open(); channel.configureBlocking(false); // only by setting this can we make the socket close event asynchronous channel.socket().setSoLinger(false, -1); channel.socket().setReuseAddress(true); channel.socket().setKeepAlive(true); channel.socket().setTcpNoDelay(true); Cluster cluster = beat.getTask().getCluster(); int port = cluster.isUseIPPort4Check() ? instance.getPort() : cluster.getDefCkport(); channel.connect(new InetSocketAddress(instance.getIp(), port)); // 注册连接、读取事件 SelectionKey key = channel.register(selector, SelectionKey.OP_CONNECT | SelectionKey.OP_READ); key.attach(beat); keyMap.put(beat.toString(), new BeatKey(key)); beat.setStartTime(System.currentTimeMillis()); GlobalExecutor .scheduleTcpSuperSenseTask(new TimeOutTask(key), CONNECT_TIMEOUT_MS, TimeUnit.MILLISECONDS); &#125; catch (Exception e) &#123; beat.finishCheck(false, false, switchDomain.getTcpHealthParams().getMax(), \"tcp:error:\" + e.getMessage()); if (channel != null) &#123; try &#123; channel.close(); &#125; catch (Exception ignore) &#123; &#125; &#125; &#125; return null; &#125; 3.3.总结Nacos的健康检测有两种模式： 临时实例： 采用客户端心跳检测模式，心跳周期5秒 心跳间隔超过15秒则标记为不健康 心跳间隔超过30秒则从服务列表删除 永久实例： 采用服务端主动健康检测方式 周期为2000 + 5000毫秒内的随机数 检测异常只会标记为不健康，不会删除 那么为什么Nacos有临时和永久两种实例呢？ 以淘宝为例，双十一大促期间，流量会比平常高出很多，此时服务肯定需要增加更多实例来应对高并发，而这些实例在双十一之后就无需继续使用了，采用临时实例比较合适。而对于服务的一些常备实例，则使用永久实例更合适。 与eureka相比，Nacos与Eureka在临时实例上都是基于心跳模式实现，差别不大，主要是心跳周期不同，eureka是30秒，Nacos是5秒。 另外，Nacos支持永久实例，而Eureka不支持，Eureka只提供了心跳模式的健康监测，而没有主动检测功能。 4.服务发现Nacos提供了一个根据serviceId查询实例列表的接口： 接口描述：查询服务下的实例列表 请求类型：GET 请求路径： /nacos/v1/ns/instance/list 请求参数： 名称 类型 是否必选 描述 serviceName 字符串 是 服务名 groupName 字符串 否 分组名 namespaceId 字符串 否 命名空间ID clusters 字符串，多个集群用逗号分隔 否 集群名称 healthyOnly boolean 否，默认为false 是否只返回健康实例 错误编码： 错误代码 描述 语义 400 Bad Request 客户端请求中的语法错误 403 Forbidden 没有权限 404 Not Found 无法找到资源 500 Internal Server Error 服务器内部错误 200 OK 正常 4.1.客户端4.1.1.定时更新服务列表4.1.1.1.NacosNamingService在2.2.4小节中，我们讲到一个类NacosNamingService，这个类不仅仅提供了服务注册功能，同样提供了服务发现的功能。 多个重载的方法最终都会进入一个方法： @Override public List&lt;Instance> getAllInstances(String serviceName, String groupName, List&lt;String> clusters, boolean subscribe) throws NacosException &#123; ServiceInfo serviceInfo; // 1.判断是否需要订阅服务信息（默认为 true） if (subscribe) &#123; // 1.1.订阅服务信息 serviceInfo = hostReactor.getServiceInfo(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; else &#123; // 1.2.直接去nacos拉取服务信息 serviceInfo = hostReactor .getServiceInfoDirectlyFromServer(NamingUtils.getGroupedName(serviceName, groupName), StringUtils.join(clusters, \",\")); &#125; // 2.从服务信息中获取实例列表并返回 List&lt;Instance> list; if (serviceInfo == null || CollectionUtils.isEmpty(list = serviceInfo.getHosts())) &#123; return new ArrayList&lt;Instance>(); &#125; return list; &#125; 4.1.1.2.HostReactor进入1.1.订阅服务消息，这里是由HostReactor类的getServiceInfo()方法来实现的： public ServiceInfo getServiceInfo(final String serviceName, final String clusters) &#123; NAMING_LOGGER.debug(\"failover-mode: \" + failoverReactor.isFailoverSwitch()); // 由 服务名@@集群名拼接 key String key = ServiceInfo.getKey(serviceName, clusters); if (failoverReactor.isFailoverSwitch()) &#123; return failoverReactor.getService(key); &#125; // 读取本地服务列表的缓存，缓存是一个Map，格式：Map&lt;String, ServiceInfo> ServiceInfo serviceObj = getServiceInfo0(serviceName, clusters); // 判断缓存是否存在 if (null == serviceObj) &#123; // 不存在，创建空ServiceInfo serviceObj = new ServiceInfo(serviceName, clusters); // 放入缓存 serviceInfoMap.put(serviceObj.getKey(), serviceObj); // 放入待更新的服务列表（updatingMap）中 updatingMap.put(serviceName, new Object()); // 立即更新服务列表 updateServiceNow(serviceName, clusters); // 从待更新列表中移除 updatingMap.remove(serviceName); &#125; else if (updatingMap.containsKey(serviceName)) &#123; // 缓存中有，但是需要更新 if (UPDATE_HOLD_INTERVAL > 0) &#123; // hold a moment waiting for update finish 等待5秒中，待更新完成 synchronized (serviceObj) &#123; try &#123; serviceObj.wait(UPDATE_HOLD_INTERVAL); &#125; catch (InterruptedException e) &#123; NAMING_LOGGER .error(\"[getServiceInfo] serviceName:\" + serviceName + \", clusters:\" + clusters, e); &#125; &#125; &#125; &#125; // 开启定时更新服务列表的功能 scheduleUpdateIfAbsent(serviceName, clusters); // 返回缓存中的服务信息 return serviceInfoMap.get(serviceObj.getKey()); &#125; 基本逻辑就是先从本地缓存读，根据结果来选择： 如果本地缓存没有，立即去nacos读取，updateServiceNow(serviceName, clusters) 如果本地缓存有，则开启定时更新功能，并返回缓存结果： scheduleUpdateIfAbsent(serviceName, clusters) 在UpdateTask中，最终还是调用updateService方法： 不管是立即更新服务列表，还是定时更新服务列表，最终都会执行HostReactor中的updateService()方法： public void updateService(String serviceName, String clusters) throws NacosException &#123; ServiceInfo oldService = getServiceInfo0(serviceName, clusters); try &#123; // 基于ServerProxy发起远程调用，查询服务列表 String result = serverProxy.queryList(serviceName, clusters, pushReceiver.getUdpPort(), false); if (StringUtils.isNotEmpty(result)) &#123; // 处理查询结果 processServiceJson(result); &#125; &#125; finally &#123; if (oldService != null) &#123; synchronized (oldService) &#123; oldService.notifyAll(); &#125; &#125; &#125; &#125; 4.1.1.3.ServerProxy而ServerProxy的queryList方法如下： public String queryList(String serviceName, String clusters, int udpPort, boolean healthyOnly) throws NacosException &#123; // 准备请求参数 final Map&lt;String, String> params = new HashMap&lt;String, String>(8); params.put(CommonParams.NAMESPACE_ID, namespaceId); params.put(CommonParams.SERVICE_NAME, serviceName); params.put(\"clusters\", clusters); params.put(\"udpPort\", String.valueOf(udpPort)); params.put(\"clientIP\", NetUtils.localIP()); params.put(\"healthyOnly\", String.valueOf(healthyOnly)); // 发起请求，地址与API接口一致 return reqApi(UtilAndComs.nacosUrlBase + \"/instance/list\", params, HttpMethod.GET); &#125; 4.1.2.处理服务变更通知除了定时更新服务列表的功能外，Nacos还支持服务列表变更时的主动推送功能。 在HostReactor类的构造函数中，有非常重要的几个步骤： 基本思路是： 通过PushReceiver监听服务端推送的变更数据 解析数据后，通过NotifyCenter发布服务变更的事件 InstanceChangeNotifier监听变更事件，完成对服务列表的更新 4.1.2.1.PushReceiver我们先看PushReceiver，这个类会以UDP方式接收Nacos服务端推送的服务变更数据。 先看构造函数： public PushReceiver(HostReactor hostReactor) &#123; try &#123; this.hostReactor = hostReactor; // 创建 UDP客户端 String udpPort = getPushReceiverUdpPort(); if (StringUtils.isEmpty(udpPort)) &#123; this.udpSocket = new DatagramSocket(); &#125; else &#123; this.udpSocket = new DatagramSocket(new InetSocketAddress(Integer.parseInt(udpPort))); &#125; // 准备线程池 this.executorService = new ScheduledThreadPoolExecutor(1, new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setDaemon(true); thread.setName(\"com.alibaba.nacos.naming.push.receiver\"); return thread; &#125; &#125;); // 开启线程任务，准备接收变更数据 this.executorService.execute(this); &#125; catch (Exception e) &#123; NAMING_LOGGER.error(\"[NA] init udp socket failed\", e); &#125; &#125; PushReceiver构造函数中基于线程池来运行任务。这是因为PushReceiver本身也是一个Runnable，其中的run方法业务逻辑如下： @Override public void run() &#123; while (!closed) &#123; try &#123; // byte[] is initialized with 0 full filled by default byte[] buffer = new byte[UDP_MSS]; DatagramPacket packet = new DatagramPacket(buffer, buffer.length); // 接收推送数据 udpSocket.receive(packet); // 解析为json字符串 String json = new String(IoUtils.tryDecompress(packet.getData()), UTF_8).trim(); NAMING_LOGGER.info(\"received push data: \" + json + \" from \" + packet.getAddress().toString()); // 反序列化为对象 PushPacket pushPacket = JacksonUtils.toObj(json, PushPacket.class); String ack; if (\"dom\".equals(pushPacket.type) || \"service\".equals(pushPacket.type)) &#123; // 交给 HostReactor去处理 hostReactor.processServiceJson(pushPacket.data); // send ack to server 发送ACK回执，略。。 &#125; catch (Exception e) &#123; if (closed) &#123; return; &#125; NAMING_LOGGER.error(\"[NA] error while receiving push data\", e); &#125; &#125; &#125; 4.1.2.2.HostReactor通知数据的处理由交给了HostReactor的processServiceJson方法： public ServiceInfo processServiceJson(String json) &#123; // 解析出ServiceInfo信息 ServiceInfo serviceInfo = JacksonUtils.toObj(json, ServiceInfo.class); String serviceKey = serviceInfo.getKey(); if (serviceKey == null) &#123; return null; &#125; // 查询缓存中的 ServiceInfo ServiceInfo oldService = serviceInfoMap.get(serviceKey); // 如果缓存存在，则需要校验哪些数据要更新 boolean changed = false; if (oldService != null) &#123; // 拉取的数据是否已经过期 if (oldService.getLastRefTime() > serviceInfo.getLastRefTime()) &#123; NAMING_LOGGER.warn(\"out of date data received, old-t: \" + oldService.getLastRefTime() + \", new-t: \" + serviceInfo.getLastRefTime()); &#125; // 放入缓存 serviceInfoMap.put(serviceInfo.getKey(), serviceInfo); // 中间是缓存与新数据的对比，得到newHosts：新增的实例；remvHosts：待移除的实例; // modHosts：需要修改的实例 if (newHosts.size() > 0 || remvHosts.size() > 0 || modHosts.size() > 0) &#123; // 发布实例变更的事件 NotifyCenter.publishEvent(new InstancesChangeEvent( serviceInfo.getName(), serviceInfo.getGroupName(), serviceInfo.getClusters(), serviceInfo.getHosts())); DiskCache.write(serviceInfo, cacheDir); &#125; &#125; else &#123; // 本地缓存不存在 changed = true; // 放入缓存 serviceInfoMap.put(serviceInfo.getKey(), serviceInfo); // 直接发布实例变更的事件 NotifyCenter.publishEvent(new InstancesChangeEvent( serviceInfo.getName(), serviceInfo.getGroupName(), serviceInfo.getClusters(), serviceInfo.getHosts())); serviceInfo.setJsonFromServer(json); DiskCache.write(serviceInfo, cacheDir); &#125; // 。。。 return serviceInfo; &#125; 4.2.服务端4.2.1.拉取服务列表接口在2.3.1小节介绍的InstanceController中，提供了拉取服务列表的接口： /** * Get all instance of input service. * * @param request http request * @return list of instance * @throws Exception any error during list */ @GetMapping(\"/list\") @Secured(parser = NamingResourceParser.class, action = ActionTypes.READ) public ObjectNode list(HttpServletRequest request) throws Exception &#123; // 从request中获取namespaceId和serviceName String namespaceId = WebUtils.optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID); String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME); NamingUtils.checkServiceNameFormat(serviceName); String agent = WebUtils.getUserAgent(request); String clusters = WebUtils.optional(request, \"clusters\", StringUtils.EMPTY); String clientIP = WebUtils.optional(request, \"clientIP\", StringUtils.EMPTY); // 获取客户端的 UDP端口 int udpPort = Integer.parseInt(WebUtils.optional(request, \"udpPort\", \"0\")); String env = WebUtils.optional(request, \"env\", StringUtils.EMPTY); boolean isCheck = Boolean.parseBoolean(WebUtils.optional(request, \"isCheck\", \"false\")); String app = WebUtils.optional(request, \"app\", StringUtils.EMPTY); String tenant = WebUtils.optional(request, \"tid\", StringUtils.EMPTY); boolean healthyOnly = Boolean.parseBoolean(WebUtils.optional(request, \"healthyOnly\", \"false\")); // 获取服务列表 return doSrvIpxt(namespaceId, serviceName, agent, clusters, clientIP, udpPort, env, isCheck, app, tenant, healthyOnly); &#125; 进入doSrvIpxt()方法来获取服务列表： public ObjectNode doSrvIpxt(String namespaceId, String serviceName, String agent, String clusters, String clientIP, int udpPort, String env, boolean isCheck, String app, String tid, boolean healthyOnly) throws Exception &#123; ClientInfo clientInfo = new ClientInfo(agent); ObjectNode result = JacksonUtils.createEmptyJsonNode(); // 获取服务列表信息 Service service = serviceManager.getService(namespaceId, serviceName); long cacheMillis = switchDomain.getDefaultCacheMillis(); // now try to enable the push try &#123; if (udpPort > 0 &amp;&amp; pushService.canEnablePush(agent)) &#123; // 添加当前客户端 IP、UDP端口到 PushService 中 pushService .addClient(namespaceId, serviceName, clusters, agent, new InetSocketAddress(clientIP, udpPort), pushDataSource, tid, app); cacheMillis = switchDomain.getPushCacheMillis(serviceName); &#125; &#125; catch (Exception e) &#123; Loggers.SRV_LOG .error(\"[NACOS-API] failed to added push client &#123;&#125;, &#123;&#125;:&#123;&#125;\", clientInfo, clientIP, udpPort, e); cacheMillis = switchDomain.getDefaultCacheMillis(); &#125; if (service == null) &#123; // 如果没找到，返回空 if (Loggers.SRV_LOG.isDebugEnabled()) &#123; Loggers.SRV_LOG.debug(\"no instance to serve for service: &#123;&#125;\", serviceName); &#125; result.put(\"name\", serviceName); result.put(\"clusters\", clusters); result.put(\"cacheMillis\", cacheMillis); result.replace(\"hosts\", JacksonUtils.createEmptyArrayNode()); return result; &#125; // 结果的检测，异常实例的剔除等逻辑省略 // 最终封装结果并返回 。。。 result.replace(\"hosts\", hosts); if (clientInfo.type == ClientInfo.ClientType.JAVA &amp;&amp; clientInfo.version.compareTo(VersionUtil.parseVersion(\"1.0.0\")) >= 0) &#123; result.put(\"dom\", serviceName); &#125; else &#123; result.put(\"dom\", NamingUtils.getServiceName(serviceName)); &#125; result.put(\"name\", serviceName); result.put(\"cacheMillis\", cacheMillis); result.put(\"lastRefTime\", System.currentTimeMillis()); result.put(\"checksum\", service.getChecksum()); result.put(\"useSpecifiedURL\", false); result.put(\"clusters\", clusters); result.put(\"env\", env); result.replace(\"metadata\", JacksonUtils.transferToJsonNode(service.getMetadata())); return result; &#125; 4.2.2.发布服务变更的UDP通知在上一节中，InstanceController中的doSrvIpxt()方法中，有这样一行代码： pushService.addClient(namespaceId, serviceName, clusters, agent, new InetSocketAddress(clientIP, udpPort), pushDataSource, tid, app); 其实是把消费者的UDP端口、IP等信息封装为一个PushClient对象，存储PushService中。方便以后服务变更后推送消息。 PushService类本身实现了ApplicationListener接口： 这个是事件监听器接口，监听的是ServiceChangeEvent（服务变更事件）。 当服务列表变化时，就会通知我们： 4.3.总结Nacos的服务发现分为两种模式： 模式一：主动拉取模式，消费者定期主动从Nacos拉取服务列表并缓存起来，再服务调用时优先读取本地缓存中的服务列表。 模式二：订阅模式，消费者订阅Nacos中的服务列表，并基于UDP协议来接收服务变更通知。当Nacos中的服务列表更新时，会发送UDP广播给所有订阅者。 与Eureka相比，Nacos的订阅模式服务状态更新更及时，消费者更容易及时发现服务列表的变化，剔除故障服务。","categories":[{"name":"springcloud","slug":"springcloud","permalink":"http://blog.b6123.top/categories/springcloud/"}],"tags":[{"name":"nacos","slug":"nacos","permalink":"http://blog.b6123.top/tags/nacos/"}]}],"categories":[{"name":"软考","slug":"软考","permalink":"http://blog.b6123.top/categories/%E8%BD%AF%E8%80%83/"},{"name":"多线程","slug":"多线程","permalink":"http://blog.b6123.top/categories/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"vue","slug":"vue","permalink":"http://blog.b6123.top/categories/vue/"},{"name":"spring","slug":"spring","permalink":"http://blog.b6123.top/categories/spring/"},{"name":"爬虫","slug":"爬虫","permalink":"http://blog.b6123.top/categories/%E7%88%AC%E8%99%AB/"},{"name":"可视化工具","slug":"爬虫/可视化工具","permalink":"http://blog.b6123.top/categories/%E7%88%AC%E8%99%AB/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/"},{"name":"springcloud","slug":"springcloud","permalink":"http://blog.b6123.top/categories/springcloud/"}],"tags":[{"name":"软考","slug":"软考","permalink":"http://blog.b6123.top/tags/%E8%BD%AF%E8%80%83/"},{"name":"JAVA源码","slug":"JAVA源码","permalink":"http://blog.b6123.top/tags/JAVA%E6%BA%90%E7%A0%81/"},{"name":"vue","slug":"vue","permalink":"http://blog.b6123.top/tags/vue/"},{"name":"springcloud","slug":"springcloud","permalink":"http://blog.b6123.top/tags/springcloud/"},{"name":"web爬虫","slug":"web爬虫","permalink":"http://blog.b6123.top/tags/web%E7%88%AC%E8%99%AB/"},{"name":"nacos","slug":"nacos","permalink":"http://blog.b6123.top/tags/nacos/"}]}